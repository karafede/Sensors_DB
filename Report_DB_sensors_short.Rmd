---
title: "Review of performance of Low-cost Sensors for Air Quality Monitoring"
author:
- Federico Karagulian, Maurizio Barbiere, Alexander Kotsev, Michel Gerboles1, Friedrich Lagler and Annette Borowiak

date: "last update `r format(Sys.time(), '%d %B %Y, %H:%M')`"
output:
  word_document: 
    reference_docx: word_style_FK.docx
  pdf_document: default
  html_document: default
  number_sections: true
  bookdown::word_document: default
bibliography: [Field_Validation_FK.bib, MyPubblications.bib, Diffusion.bib, MACPoll.bib]
# csl: sensors.csl
csl: nature.csl
# csl: atmospheric-environment.csl
link-citations: yes
header-includes:
  - \usepackage{xcolor}
  - \usepackage{framed}
  - \pagenumbering{arabic}
...

\newline

## Abstract

A growing number of companies started commercialising low-cost sensors (LCS) that are said to be able to monitor air pollution in outdoor air. The benefit about the use of LCS is the increased spatial coverage when monitoring air quality in cities and remote locations. Today, there are hundreds of LCSs commercially available on the market with a cost ranging from a few hundred to a few thousand euro. At the same time, independent evaluation of the performance of LCSs against reference measurements is only available in literature for about 110 LCSs in literature. These studies report that LCS are unstable and often affected by atmospheric condition, cross sensitivities from interfering compounds that may change LCS performance depending on site location. In this work, quantitative data about the performance of tested LCS against reference measurement are presented. This information was gathered from published reports and relevant testing laboratories. Other information was drawn from peer-reviewed journals that tested different types of LCSs in research studies. Relevant metrics about the comparison of LCSs systems against reference systems highlighted the most cost-effective LCSs that could be used to monitor air quality pollutants with a good level of agreement represented by a coefficient of determination of $R^2$ > 0.75 and slope close to 1.0. This review highlights the possibility to have versatile LCSs able to operate with multiple pollutants and  preferably with transparent LCS data treatment.



All references here [@aleixandre_review_2012; @alvarado_towards_2015; @aq-spec_air_2015; @austin_laboratory_2015; @badura_optical_2018; @barrett_coefficient_1974; @bettair_bettair_2017; @bigi_performance_2018; @borghi_precision_2018; @borrego_assessment_2016; @budde_suitability_2018; @castell_can_2017; @cavaliere_development_2018; @cen_ambient_2012_CO; @cen_ambient_2012_NO2; @cen_ambient_2012_O3; @cen_ambient_2012_SO2; @cen_ambient_2014_PM; @chakrabarti_performance_2004; @cordero_using_2018; @crilley_evaluation_2018; @cross_use_2017; @crunaire_1er_2018; @dacunto_determining_2015; @de_vito_calibrating_2018; @di_antonio_developing_2018; @directive_2008_50_ec; @duvall_performance_2016; @esposito_dynamic_2016; @european_commission_guide_2010; @feinberg_long-term_2018; @fishbain_evaluation_2017; @gao_distributed_2015; @gerboles_airsenseur_2015; @gillooly_development_2019; @han_feasibility_2017; @holstius_field_2014; @iscape_summary_2017; @jiao_community_2016; @jovasevic-stojanovic_use_2015; @karagulian_calibration_2019; @karagulian_evaluation_2012; @kelly_ambient_2017; @key-vocs_metrology_2017; @kumar_rise_2015; @kunak_wireless_2017; @laquai_particle_2017; @lewis_low-cost_2018; @lewis_validate_2016; @lin_evaluation_2015; @liu_performance_2019; @manikonda_laboratory_2016; @marjovi_extending_2017; @mead_use_2013; @mijling_practical_2017; @mueller_design_2017; @mukherjee_assessing_2017; @northcross_low-cost_2013; @olivares_outdoor_2015; @piedrahita_next_2014; @pillarisetti_small_2017; @popoola_development_2016; @snyder_changing_2013; @sousan_evaluation_2016; @sousan_inter-comparison_2016; @spinelle_evaluation_2016; @spinelle_evaluation_2017; @spinelle_field_2015; @spinelle_field_nodate; @spinelle_performance_2015; @spinelle_report_2013; @spinelle_report_2013-1; @steinle_personal_2015; @sun_development_2016; @sun_development_2017; @the_world_air_quality_index_sensing_2019; @thunis_performance_2012; @united_states_environmental_protection_agency_evaluation_2015; @vaughn_characterization_2010; @viana_field_2015; @wang_laboratory_2015; @wastine_airsenseur_2019; @wastine_essai_2019; @wei_impact_2018; @white_sensors_2012; @williams_air_2014; @williams_deliberating_2019; @williams_evaluation_2014; @williams_sensor_2014; @zheng_field_2018; @zhou_recent_2015; @zikova_estimating_2017; @zimmerman_machine_2018]



```{r , echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE, include=FALSE}

library(readxl)
library(dplyr)
library(lubridate)
library(tidyr)
library(readr)
library(stringr)
library(tools)
library(ggplot2)
library(ggpmisc)
library(xtable)
library(pander)
library(formattable)
library(rmarkdown)
library(knitr)
library(kableExtra)
library(forcats)
library(bookdown)
library(ggrepel)
library(httr)
library(scales)

# only run this part when @ the JRC
PROXY = TRUE; URL      = "10.168.209.72"; PORT     = 8012; LOGIN    = NULL; PASSWORD = NULL
# no login and no password on our proxy
      if (PROXY) {
          # checking that we have the httr package to use function Set_Config()
          library("httr")
          cat("[CONFIG] INFO Package httr loaded\n")
          # implement PROXY
          set_config(use_proxy(url=URL, port=PORT, username = LOGIN, password = PASSWORD))
      } else reset_config()


# All [@spinelle_report_2013; @spinelle_report_2013-1; @aq-spec_air_2015; @williams_evaluation_2014; @feinberg_long-term_2018; @mukherjee_assessing_2017; @sousan_evaluation_2016; @crilley_evaluation_2018; @borrego_assessment_2016; @united_states_environmental_protection_agency_evaluation_2015; @jiao_community_2016; @manikonda_laboratory_2016; @sousan_inter-comparison_2016; @northcross_low-cost_2013; @holstius_field_2014; @steinle_personal_2015; @han_feasibility_2017; @jovasevic-stojanovic_use_2015; @dacunto_determining_2015; @borghi_precision_2018; @sun_development_2016; @cavaliere_development_2018; @castell_can_2017; @spinelle_performance_2015; @spinelle_field_2015; @spinelle_field_nodate; @williams_sensor_2014; @zimmerman_machine_2018; @vaughn_characterization_2010; @sun_development_2017; @lin_evaluation_2015; @karagulian_evaluation_2012; @zheng_field_2018; @duvall_performance_2016; @mijling_practical_2017; @mead_use_2013; @wang_laboratory_2015; @cross_use_2017; @cordero_using_2018; @mueller_design_2017; @alvarado_towards_2015; @olivares_outdoor_2015; @austin_laboratory_2015; @gao_distributed_2015; @kelly_ambient_2017; @zikova_estimating_2017; @viana_field_2015; @piedrahita_next_2014; @wei_impact_2018; @gerboles_airsenseur_2015; @chakrabarti_performance_2004; @laquai_particle_2017; @budde_suitability_2018; @badura_optical_2018; @pillarisetti_small_2017; @gillooly_development_2019; @karagulian_calibration_2019; @spinelle_evaluation_2016; @kunak_wireless_2017; @bettair_bettair_2017; @popoola_development_2016; @marjovi_extending_2017; @bigi_performance_2018; @spinelle_evaluation_2017; @kumar_rise_2015; @lewis_validate_2016; @cen_ambient_2012_CO; @cen_ambient_2012_NO2; @cen_ambient_2012_O3; @cen_ambient_2012_SO2; @cen_ambient_2014_PM; @key-vocs_metrology_2017; @lewis_low-cost_2018; @barrett_coefficient_1974; @the_world_air_quality_index_sensing_2019; @liu_performance_2019; @iscape_summary_2017; @snyder_changing_2013; @aleixandre_review_2012; @white_sensors_2012; @zhou_recent_2015; @williams_air_2014; @crunaire_1er_2018; @wastine_essai_2019; @wastine_airsenseur_2019; @di_antonio_developing_2018; @directive_2008_50_ec; @williams_deliberating_2019; @fishbain_evaluation_2017; @esposito_dynamic_2016; @european_commission_guide_2010; @thunis_performance_2012; @de_vito_calibrating_2018]

# Set global options
# options(stringsAsFactors = TRUE)
# no scientific format
# options(scipen=999)

# setwd("L:/ERLAP/Diffusion/AQSens/Deliverables/2.1 review")
# setwd("C:/JRC_CA/AA AQSens")

# import DB data

### read from GoogleDrive ###############################

myurl <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSsQGWrp2KAqEDdqM6usR8B3-iLCWDHHLGODOHIvDZGunaeBExnf3JNRIpEwFlFLtoWgJ8dezp6MIPg/pub?output=xlsx"


GET(myurl, write_disk(tf <- tempfile(fileext = ".xlsx")))
DB <- readxl::read_excel(tf, sheet = 1)

# read bibliography sheet from the DB
DB_bib <- readxl::read_excel(tf, sheet = 2)
########################################################
########################################################

# DB <- readxl::read_excel("DB_sensor_types.xlsx",
#                                 sheet = 1)

# read bibliography sheet from the DB
# DB_bib <- readxl::read_excel("DB_sensor_types.xlsx",
#                                 sheet = 4)


# order in alphabetic order
DB_bib <- DB_bib[order(DB_bib$reference),]

# assign an ID to references (mantain the same order as in the DB)
# DB$ID_reference <- as.numeric(as.factor(DB$reference))
DB_bib$ID_reference <- as.numeric(factor(DB_bib$reference, levels = unique(DB_bib$reference)))


# UNIQUE LIST of REFERENCES TO BE INSERTED IN THE SAME ORDER!!!!!
list_DB_bib <-  DB_bib[!duplicated(DB_bib[c("ID_reference")]),] 

write.csv(list_DB_bib, "list_DB_bib.csv")

# merge DB with DB_bib
DB$ID_ref <- data.frame(DB_bib[match(DB$reference, table = DB_bib$reference), "ID_reference"])

DB <- DB %>%
  mutate(time_AVG = paste(`Averaging time`, `units (avg_time)`))

DB <- as.matrix(DB)
DB <- as.data.frame(DB)

# data cleaning
headers <- names(DB)
headers <- str_replace_all(headers, "\\.|\\(|\\)", "")
headers <- make.names(headers, unique = TRUE)
headers <- str_replace_all(headers, "\\.", "_")
headers <- str_to_lower(headers)

# Give table headers
names(DB) <- headers

write.csv(DB, "DB.csv")
DB <- read.csv("DB.csv", header = TRUE)

# remove rows with NA
DB <- DB[!(is.na(DB$model)), ]

# remove columns with NA from the first column
# DB <- DB[colSums(!is.na(DB)) > 0]


names(DB)[names(DB)=="oem___sensor_system1"] <- "OEM_system"
names(DB)[names(DB)=="typeopc__nephelometer__electrochemical__metal_oxide"] <- "type_sensor"
names(DB)[names(DB)=="open_source_correction_or_black_box_"] <- "open_close"


# create a new referecne with number (ID) of the reference and first author name 
DB$new_ref <-NA
DB$new_ref_author <-NA
ref <- strsplit(x = as.character(DB$reference), "\\, |\\_| ")  # space "" and "_"

for (i in 1:length(ref)) {
    ref[[i]][1]
   DB$new_ref[i] <- paste0(ref[[i]][1], "[", DB$id_ref[i], "]") 
} 

for (i in 1:length(ref)) {
    ref[[i]][1]
   DB$new_ref_author[i] <- ref[[i]][1] 
} 

# select only few field of interest
DB <- DB %>%
  select(manufacturer,
         project,
         model,
         pollutant,
         sensor_result_unit,
         OEM_system,
         open_close,
         field___lab,
         site,
         time_avg,
         r2,
         r2_calib,
         rmse,
         u,
         intercept,
         slope,
         reference,
         year_ref,
         type_sensor,
         model_type_calibration,
         x, y,
         price,
         living,
         commercial,
         currency,
         id_ref,
         new_ref,
         new_ref_author)

# filter out model KUNAKAIR and Bettair for now...
DB <- DB %>%
  filter(!model %in% c("KUNAKAIR P10 V2", "KUNAKAIR A10 V2", "Bettair"))


# for now filter out the pollutant "NO"
# DB <- DB %>%
#   filter(!pollutant == "NO")


# replace "sensor system" with SS
levels(DB$OEM_system) <- gsub("^sensor system$","SS", levels(DB$OEM_system))

#rename N in "commercial" with "NC"
levels(DB$commercial) <- gsub("^N$","NC", levels(DB$commercial))
levels(DB$commercial) <- gsub("^Y$","", levels(DB$commercial))

# n. records
n_DB_length <- nrow(DB) # n.records

# n. OEM records
DB_length_OEM <- DB %>%
  filter(OEM_system == "OEM")
n_DB_length_OEM <- nrow(DB_length_OEM)

# n. SS records
DB_length_SS <- DB %>%
  filter(OEM_system == "SS")
n_DB_length_SS <- nrow(DB_length_SS)


# n.records "living"
n_DB_length_records_living <- DB %>% 
 filter(living %in% c("Y", "updated"))
n_DB_length_records_living <- nrow(n_DB_length_records_living)

# n.records "non-living"
n_DB_length_records_non_living <- DB %>% 
  filter(living %in% c("N"))
n_DB_length_records_non_living <- nrow(n_DB_length_records_non_living)


# n.records "living" OEM
n_DB_length_records_living_OEM <- DB %>% 
 filter(living %in% c("Y", "updated"),
        OEM_system == "OEM")
n_DB_length_records_living_OEM <- nrow(n_DB_length_records_living_OEM)


# n.records "living" SS
n_DB_length_records_living_SS <- DB %>% 
 filter(living %in% c("Y", "updated"),
        OEM_system == "SS")
n_DB_length_records_living_SS <- nrow(n_DB_length_records_living_SS)


# n.records "non-living" OEM
n_DB_length_records_non_living_OEM <- DB %>% 
 filter(living %in% c("N"),
        OEM_system == "OEM")
n_DB_length_records_non_living_OEM <- nrow(n_DB_length_records_non_living_OEM)


# n.records "non-living" SS
n_DB_length_records_non_living_SS <- DB %>% 
 filter(living %in% c("N"),
        OEM_system == "SS")
n_DB_length_records_non_living_SS <- nrow(n_DB_length_records_non_living_SS)



# manufacturers
DB_manufacturer <- DB[!duplicated(DB[c("manufacturer")]),] # manufacturers

# manufacturers - OEM
DB_manufacturers_OEM <- DB_manufacturer %>%
  filter(OEM_system == "OEM")
n_DB_manufacturers_OEM <- nrow(DB_manufacturers_OEM)

# manufacturers -SS
DB_manufacturers_SS <- DB_manufacturer %>%
  filter(OEM_system == "SS")
n_DB_manufacturers_SS <- nrow(DB_manufacturers_SS)


n_manufacturer_count <- count(DB[!duplicated(DB[c("manufacturer")]),]) # n. manufacturers
n_projects_count <- count(DB[!duplicated(DB[c("project")]),]) # n. projects
n_model_count <- count(DB[!duplicated(DB[c("model")]),])
n_references <- count(DB[!duplicated(DB[c("reference")]),]) # n. sources
n_system <- count(DB[!duplicated(DB[c("OEM_system")]),])
n_UNCERTAINITY_count <- count(DB[!duplicated(DB[c("rmse", "u")]),]) # n. records reporting uncertainties (RMSE or U)

# references reporting RMSE
rmse_references <- DB[!(is.na(DB$rmse)), ]
rmse_references <- count(rmse_references[!duplicated(rmse_references[c("reference")]),]) # n. references reporting RMSE
# references reporting Uncertainty U (mostly standard deviation)
u_references <- DB[!(is.na(DB$u)), ]
u_references <- count(u_references[!duplicated(u_references[c("reference")]),]) # n. references reporting U
uncertainty_references <- rmse_references + u_references


# check how many records for different time averages (CALIBRATION)
time_AVG_calib <- DB %>%
  group_by(time_avg,
           OEM_system) %>%
  filter(!is.na(r2_calib)) %>%
   summarise(counts = length(time_avg))
AVG_1_hour_calib_OEM <- time_AVG_calib$counts[1]
AVG_1_hour_calib_SS <- time_AVG_calib$counts[2]
AVG_1_hour_calib <- AVG_1_hour_calib_OEM + AVG_1_hour_calib_SS
AVG_1_min_calib_OEM <- time_AVG_calib$counts[3]
AVG_1_min_calib_SS <- time_AVG_calib$counts[4]
AVG_1_min_calib <- AVG_1_min_calib_OEM + AVG_1_min_calib_SS
AVG_calib_OEM <- AVG_1_hour_calib_OEM + AVG_1_min_calib_OEM
AVG_calib_SS <- AVG_1_hour_calib_SS + AVG_1_min_calib_SS


# check how many records for different time averages (COMPARISON)
time_AVG_comp <- DB %>%
  group_by(time_avg,
           OEM_system) %>%
  filter(!is.na(r2)) %>%
   summarise(counts = length(time_avg))
AVG_1_hour_comp_OEM <- time_AVG_comp$counts[1]
AVG_1_hour_comp_SS <- time_AVG_comp$counts[2]
AVG_1_hour_comp <- AVG_1_hour_comp_OEM + AVG_1_hour_comp_SS
AVG_1_min_comp_OEM <- time_AVG_comp$counts[3]
AVG_1_min_comp_SS <- time_AVG_comp$counts[4]
AVG_1_min_comp <- AVG_1_min_comp_OEM + AVG_1_min_comp_SS
AVG_comp_OEM <- AVG_1_hour_comp_OEM + AVG_1_min_comp_OEM
AVG_comp_SS <- AVG_1_hour_comp_SS + AVG_1_min_comp_SS

# select only sensors that have not been discontinued
DB_unique_model <- DB[!duplicated(DB[c("model")]),]
DB_living <- DB_unique_model %>%
   filter(living %in% c("Y", "updated"))
n_DB_length_living <- nrow(DB_living) # n.records of living sensors

DB_living_OEM <- DB_unique_model %>%
   filter(living %in% c("Y", "updated"),
          OEM_system == "OEM")
n_DB_length_living_OEM <- nrow(DB_living_OEM) # n.records of living sensors OEM

DB_living_SS <- DB_unique_model %>%
   filter(living %in% c("Y", "updated"),
          OEM_system == "SS")
n_DB_length_living_SS <- nrow(DB_living_SS) # n.records of living sensors SS


# number of non living sensors
DB_non_living <- DB_unique_model %>%
   filter(living %in% c("N"))
n_DB_length_non_living <- nrow(DB_non_living) # n.records of living sensors

DB_non_living_OEM <- DB_unique_model %>%
   filter(living %in% c("N"),
          OEM_system == "OEM")
n_DB_length_non_living_OEM <- nrow(DB_non_living_OEM) # n.records of living sensors OEM

DB_non_living_SS <- DB_unique_model %>%
   filter(living %in% c("N"),
          OEM_system =="SS")
n_DB_length_non_living_SS <- nrow(DB_non_living_SS) # n.records of living sensors SS


count_OEM_systems <- DB %>%
  group_by(OEM_system) %>%
  summarise(counts = length(OEM_system),
            references = paste(unique(id_ref), collapse=","))


# counts Open Source or black box RECORDS
DB_open_model <- DB[!(is.na(DB$model)), ]

count_open_source_systems <- DB %>%
  group_by(open_close,
           OEM_system) %>%
  summarise(counts = length(open_close))


open_source_SS <- count_open_source_systems$counts[4]
black_box_SS <- count_open_source_systems$counts[2]

open_source_OEM <- count_open_source_systems$counts[3]
black_box_OEM <- count_open_source_systems$counts[1]

open_source <- count_open_source_systems$counts[4] + count_open_source_systems$counts[3]
black_box <- count_open_source_systems$counts[2] + count_open_source_systems$counts[1]


###### OPEN SOURCE / BLACK BOX models  #########################
################################################################

DB_open_source_model <- DB %>%
  filter(open_close == "open source")
n_open_source <- count(DB_open_source_model[!duplicated(DB_open_source_model[c("model")]),]) # n. open source models

DB_black_box_model <- DB %>%
  filter(open_close == "black box")
n_black_box <- count(DB_black_box_model[!duplicated(DB_black_box_model[c("model")]),]) # n. black box model

###### COMMERCIAL sensors
DB_commercial_OEM <- DB %>%
  filter(commercial == "",
        OEM_system == "OEM")
n_DB_commercial_OEM <- nrow(DB_commercial_OEM)
DB_commercial_OEM <- count(DB_commercial_OEM[!duplicated(DB_commercial_OEM[c("model")]),]) 

DB_commercial_SS <- DB %>%
  filter(commercial == "",
        OEM_system == "SS")
n_DB_commercial_SS <- nrow(DB_commercial_SS)
DB_commercial_SS <- count(DB_commercial_SS[!duplicated(DB_commercial_SS[c("model")]),]) 

DB_commercial <- DB_commercial_SS + DB_commercial_OEM


###### COMMERCIAL / non-COMMERICAL sensors
DB_non_commercial_OEM <- DB %>%
  filter(commercial == "NC",
        OEM_system == "OEM")
n_DB_non_commercial_OEM <- nrow(DB_non_commercial_OEM)
DB_non_commercial_OEM <- count(DB_non_commercial_OEM[!duplicated(DB_non_commercial_OEM[c("model")]),]) 

DB_non_commercial_SS <- DB %>%
  filter(commercial == "NC",
        OEM_system == "SS")
n_DB_non_commercial_SS <- nrow(DB_non_commercial_SS)
DB_non_commercial_SS <- count(DB_non_commercial_SS[!duplicated(DB_non_commercial_SS[c("model")]),]) 

DB_non_commercial <- DB_non_commercial_SS + DB_non_commercial_OEM


########################################
##### Open source / black box ##########
########################################

# Open source OEM MODELS
DB_open_source_model_OEM <- DB %>%
  filter(open_close == "open source",
         OEM_system == "OEM")
n_open_source_OEM <- count(DB_open_source_model_OEM[!duplicated(DB_open_source_model_OEM[c("model")]),]) # n. open source models OEM

# Open source SS MODELS
DB_open_source_model_SS <- DB %>%
  filter(open_close == "open source",
         OEM_system == "SS")
n_open_source_SS <- count(DB_open_source_model_SS[!duplicated(DB_open_source_model_SS[c("model")]),]) # n. open source models SS

n_open_source <- n_open_source_OEM + n_open_source_SS



# Black box OEM MODELS
DB_black_box_model_OEM <- DB %>%
  filter(open_close == "black box",
         OEM_system == "OEM")
n_black_box_OEM <- count(DB_black_box_model_OEM[!duplicated(DB_black_box_model_OEM[c("model")]),]) # n. black box model OEM


# Black box SS MODELS
DB_black_box_model_SS <- DB %>%
  filter(open_close == "black box",
         OEM_system == "SS")
n_black_box_SS <- count(DB_black_box_model_SS[!duplicated(DB_black_box_model_SS[c("model")]),]) # n. black box model SS

n_black_box <- n_black_box_OEM + n_black_box_SS


#######################################################################
#######################################################################
# only select open source sensors
# DB <- DB %>%
#   filter(open_close == "open source")

OEM <- count_OEM_systems$counts[1]
SS <- count_OEM_systems$counts[2]

DB_OEM <- DB %>%
  filter(OEM_system == "OEM")
n_OEM_count <- count(DB_OEM[!duplicated(DB_OEM[c("model")]),]) # n. OEMs

DB_SS <- DB %>%
  filter(OEM_system == "SS")
n_SS_count <- count(DB_SS[!duplicated(DB_SS[c("model")]),]) # n. n. SS


## counts LAB/FIELD tests
count_tests <- DB %>%
  group_by(field___lab) %>%
  summarise(counts = length(field___lab))

field_tests <- count_tests$counts[1]
lab_tests <- count_tests$counts[2]

###########################
## Particulate Matter #####
###########################

# count sensor types
PM_sensors_counts <- DB %>%
  filter(pollutant %in% c("PM10", "PM2.5", "PM1", "PM10-2.5", "PM2.5-0.5", "PM3", "PM2", "PM")) %>%
  group_by(type_sensor) %>%
  summarise(counts = length(type_sensor),
             references = paste(unique(id_ref), collapse=","))

####################################################################
# find pollutants for each type of sensor for Particulate Matter ###
####################################################################

poll_PM_sensors_counts <- DB %>%
  group_by(type_sensor,
           pollutant) %>%
  summarise(counts = length(type_sensor),
             references = paste(unique(id_ref), collapse=",")) %>%
  filter(pollutant %in% c("PM10", "PM2.5", "PM1", "PM10-2.5", "PM2.5-0.5", "PM3", "PM2", "PM"))

# rename pollutants
levels(poll_PM_sensors_counts$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(poll_PM_sensors_counts$pollutant))
levels(poll_PM_sensors_counts$pollutant) <- gsub("^PM2$","PM2.5", levels(poll_PM_sensors_counts$pollutant))
levels(poll_PM_sensors_counts$pollutant) <- gsub("^PM3$","PM2.5", levels(poll_PM_sensors_counts$pollutant))
levels(poll_PM_sensors_counts$pollutant) <- gsub("^PM10-2.5$","PM10", levels(poll_PM_sensors_counts$pollutant))
levels(poll_PM_sensors_counts$pollutant) <- gsub("^PM$","PM2.5", levels(poll_PM_sensors_counts$pollutant))

levels(poll_PM_sensors_counts$pollutant) <- gsub("^PM2.5$","$PM_{2.5}$", levels(poll_PM_sensors_counts$pollutant))
levels(poll_PM_sensors_counts$pollutant) <- gsub("^PM10$","$PM_{10}$", levels(poll_PM_sensors_counts$pollutant))
levels(poll_PM_sensors_counts$pollutant)<- gsub("^PM1$","$PM_{1}$", levels(poll_PM_sensors_counts$pollutant))

# .....group again...
poll_PM_sensors_counts <- poll_PM_sensors_counts %>%
  group_by(type_sensor,
           pollutant) %>%
  summarise(counts = length(type_sensor),
             references = paste(unique(references), collapse=","))

pollutants_PM_sensor_type <- poll_PM_sensors_counts %>%
  group_by(type_sensor) %>%
  summarise(pollutant = paste(unique(pollutant), collapse=","))

#####################################################################
#####################################################################

sum_PM_counts <- sum(PM_sensors_counts$counts)
OPC <- PM_sensors_counts$counts[3]
neph <- PM_sensors_counts$counts[2]

Optical_tests <- PM_sensors_counts$counts[2] + PM_sensors_counts$counts[3]

PM_sensors_counts <- cbind(PM_sensors_counts, pollutants_PM_sensor_type[,2])
names(PM_sensors_counts)[names(PM_sensors_counts)=="counts"] <- "n. records"
PM_sensors_counts <- PM_sensors_counts %>%
  select(type_sensor,
         pollutant,
         `n. records`,
         references)

##############
# Gases ######
##############

GAS_sensors_counts <- DB %>%
  filter(pollutant %in% c("CO", "NO", "NO2", "O3", "NO2-O3")) %>%
  group_by(type_sensor) %>%
  summarise(counts = length(type_sensor),
            references = paste(unique(id_ref), collapse=","))

GAS_sensors_counts_electrochemical <- GAS_sensors_counts[1,2] 
GAS_sensors_counts_MOS <- GAS_sensors_counts[2,2]

####################################################################
# find pollutants for each type of sensor for Gases ################
####################################################################

poll_GAS_sensors_counts <- DB %>%
  group_by(type_sensor,
           pollutant) %>%
  summarise(counts = length(type_sensor),
             references = paste(unique(id_ref), collapse=",")) %>%
  filter(pollutant %in% c("CO", "NO", "NO2", "O3", "NO2-O3"))

levels(poll_GAS_sensors_counts$pollutant) <- gsub("^NO2$","$NO_{2}$", levels(poll_GAS_sensors_counts$pollutant))
levels(poll_GAS_sensors_counts$pollutant) <- gsub("^O3$","$O_{3}$", levels(poll_GAS_sensors_counts$pollutant))
levels(poll_GAS_sensors_counts$pollutant) <- gsub("^CO$","$CO$", levels(poll_GAS_sensors_counts$pollutant))
levels(poll_GAS_sensors_counts$pollutant) <- gsub("^NO$","$NO$", levels(poll_GAS_sensors_counts$pollutant))

# .....group again...
poll_GAS_sensors_counts <- poll_GAS_sensors_counts %>%
  group_by(type_sensor,
           pollutant) %>%
  summarise(counts = length(type_sensor),
             references = paste(unique(references), collapse=","))

pollutants_GAS_sensor_type <- poll_GAS_sensors_counts %>%
  group_by(type_sensor) %>%
  summarise(pollutant = paste(unique(pollutant), collapse=","))

#####################################################################
#####################################################################

GAS_sensors_counts <- cbind(GAS_sensors_counts, pollutants_GAS_sensor_type[,2])
names(GAS_sensors_counts)[names(GAS_sensors_counts)=="counts"] <- "n. records"
GAS_sensors_counts <- GAS_sensors_counts %>%
  select(type_sensor,
         pollutant,
         `n. records`,
         references)

# bind Particulate Matter with Gases ###

PM_GAS_sensors_counts <- rbind(PM_sensors_counts,
                               GAS_sensors_counts)
names(PM_GAS_sensors_counts)[names(PM_GAS_sensors_counts)=="type_sensor"] <- "type"

# make all references as superscript
PM_GAS_sensors_counts$references <- paste0("$@^{", format(unlist(PM_GAS_sensors_counts$references)),"}$")



# statistics of the MEDIAN of R2 for COMPARISON and CALIBRATION

DB_R2 <- DB[!is.na(DB$r2 & DB$r2_calib), ]
DB_R2 <- DB_R2 %>%
  filter(r2 > 0,
         r2_calib > 0) %>%
  summarise(median_R2_CALIB = median(r2_calib, na.rm = T),
            median_R2       = median(r2, na.rm = T),
            mean_R2_CALIB = mean(r2_calib, na.rm = T),
            mean_R2       = mean(r2, na.rm = T))
  


```

\newline

## 1. Introduction

The widening of the commercial availability of micro-sensors technology is contributing to the rapid adoption of low-cost sensors for air quality monitoring by both citizen science initiatives and public authorities [@kumar_rise_2015].In general, public authorities want to increase the density of monitoring measurements and often want to rely on low-cost sensors because they cannot afford any reference Air Quality Monitoring Station (AQMS) [@directive_2008_50_ec].Low-cost sensors can provide real time measurements at lower cost allowing higher spatial coverage than the current reference methods for air pollutants measurements. Additionally, the monitoring of air pollution with reference measurement methods requires skilled operators for the maintenance and calibration of measuring devices that are described in detailed Standard Operational Procedures [@cen_ambient_2012_CO; @cen_ambient_2012_NO2; @cen_ambient_2012_O3; @cen_ambient_2012_SO2; @cen_ambient_2014_PM]. Conversely, it is expected that low-cost sensors can be operated without human intervention making it possible for unskilled users to monitor air pollution without the need of additional technical knowledge.
Plenty of institutes in charge of air quality monitoring for regulatory purposes, as well as local authorities, are considering to include low-cost sensors within their routine method of measurements to supplement monitoring with reference measurements. However, the lack of exhaustive and accessible information in order to compare the performance of low-cost sensors and the wide commercial offer make it difficult to select the most appropriate low-cost sensors for monitoring purposes. 
For classification and understanding of sensor deployment, one should distinguish between the sole sensor detector produced by Original Equipment Manufacturer (hereafter such sensors are called OEM, or OEM sensors) and sensor systems (SSys), which include OEM sensors together with a protective box, sampling system, power system, electronic hardware, and software for data acquisition, analogue to digital conversion, data treatment and data transfer [@lewis_validate_2016].Hereafter, OEM and SSys are referred to as low-cost sensors (LCS). From a user point of view, SSys are ready to use out of the box systems, while OEMs needs users to add hardware/software components for protection from meteorological conditions, data storage, data pushing, interoperability of data and generally the calibration of LCSs. The use of LCSs is of major interest for citizen-science initiatives. Therefore, Small and Medium Enterprises make SSys available which can be deployed by citizens who want to monitor the air quality in a chosen environment.

Although a number of reviews of the suitability of LCS for ambient air quality have been published [@iscape_summary_2017; @aleixandre_review_2012; @snyder_changing_2013; @kumar_rise_2015; @white_sensors_2012; @castell_can_2017; @zhou_recent_2015; @williams_air_2014], quantitative data for comparing and evaluating the agreement between LCS and reference data are mostly missing in the existing reviews. Additionally, there is no commonly accepted protocol for the test of LCS [@williams_deliberating_2019] and the metrics reported are generally diverse making it difficult to compare the performance of LCS between evaluation studies.
Among the available tests of LCS, there are clear indications that the accuracy of LCS measurements can be questionable [@aq-spec_air_2015; @spinelle_field_2015] when comparing LSC values and reference measurements. LCS data can be of variable quality, and it is therefore of fundamental importance to evaluate LCS in order to choose the most appropriate ones for routine measurements or other case studies[@lewis_validate_2016]. However, only a few independent tests are reported in academic publications. 
Hereafter, the results of the exhaustive review of existing literature on LCS evaluation that is not available elsewhere are presented. The main purpose of this review was to estimate the agreement between LCS data against reference measurements both with field and tests under controlled conditions carried out by laboratories and research institutes independent from sensor manufacturers and commercial interest. It can provide all stakeholders with exhaustive information for selecting the most appropriate LCS. Quantitative information was gathered from the existing literature about the performance of LCS according to the following criteria:
1. Agreement between LCS and reference measurements
2. Availability of raw data, transparency of data treatment making a-posteriori calibration possible
3. Capability to measure multiple pollutants
4. Affordability of LCSs taking into consideration the number of provided OEMs


\newline

## 2. Sources of available information, method of classification and evaluation

### 2.1. Origin of data

The research was focused on LCS for Particulate Matter (PM), ozone (O3), nitric dioxide (NO2) and carbon monoxide (CO), the pollutants that are included into the European Union Air Quality Directive [@directive_2008_50_ec]. References were also included for nitrogen monoxide LCSs. 

About *`r n_DB_length`* independent laboratory or field tests of LCS versus reference measurements (called ‘Records’ in the rest of the manuscript) were gathered from peer-reviewed studies of LCS available in the Scopus database, the World Wide Web, the AirMontech website (http://db-airmontech.jrc.ec.europa.eu/search.aspx), ResearchGate, Google search, and reports from research laboratories. Sensor validation studies provided by LCS manufacturers or other sources with concern of a possible conflict of interest were not taken into consideration. Overall, *`r n_references`* independent studies were found from different sources including reports and peer-reviewed papers. 
Additionally, a significant number of test results came from reports published by research institutes. In fact, the rapid technological progress on LCS, the difficulty to publish LCS data that do not agree with reference measurements and the time needed to publish studies in academic journals makes the publication of articles not the preferred route. Consequently,  a great part of the available information is found in grey literature, mainly in the form of reports. A substantial quantity of presented results come from research institutes having a LCS testing program in place, e.g. the Air Quality Sensor Performance Evaluation Center (AQ-SPEC)[@aq-spec_air_2015], the European Union Joint Research Centre (EU JRC) [@aleixandre_review_2012; @spinelle_evaluation_2016; @spinelle_evaluation_2017; @spinelle_field_2015; @spinelle_field_nodate; @spinelle_performance_2015; @spinelle_report_2013; @spinelle_report_2013-1; @gerboles_airsenseur_2015; @karagulian_calibration_2019],and the United States Environmental Protection Agency (US EPA) [@williams_air_2014; @williams_deliberating_2019; @williams_evaluation_2014; @williams_sensor_2014; @vaughn_characterization_2010]. 

A significant portion of the data comes from the first French field intercomparison exercise (Crunaire [@crunaire_1er_2018]) for gas and particle LCS carried out in January/February of 2018. This exercise was carried out by two members of the French Reference Laboratory for Air Quality Monitoring (LCSQA). The objective of the study was to test LCS under field conditions at Air Quality Monitoring Station of urban type sited at the IMT Lille Douai research facilities in Dorignies. A large number of different SSys and OEM were installed in order to evaluate their ability to monitor the main pollutants of interest in the ambient air: NO2, O3 and PM2.5/PM10. This exercise involved nearly 5 French laboratories in charge of air pollution monitoring and 10 companies (manufacturers or distributors/sellers), 23 SSys and OEM of different design and origin (France, Netherlands, United Kingdom, Spain, Italy, Poland, United States), for a total of more than sixty devices, when taking into account replicates.

Within another project, called AirLab (http://www.airlab.solutions/), many LCSs were tested through field and indoor tests. Results are reported based on the Integrated Performance Index  (IPI) developed by Fishbain et al. [@fishbain_evaluation_2017] which is an integrated indicator of correlation, bias, failure, source apportionment with LCS, accuracy and time series variability of LCSs and reference measurements. Since the IPI is not available in other studies and cannot be compared with the metrics used in the current review, it was decided not to include the AirLab results in the current work. 

A shared database of laboratory and field test results and its associated scripts for summary statistics were created using the collected information. It will be possible to update the database with future results of LCS tests. The purpose of this development was to setup a structured repository to be used for comparing the performances of LCSs. 
Each database ‘Record’ describing laboratory or field LCS test results was included into the database only if comparison against a reference measurement (hereinafter defined as “comparison”) was provided. The comparison data allowed to evaluate the correlation between LCS data and reference measurements. Most of the reviewed studies reported only regression parameters obtained from the comparison between LCS and reference measurements, generally without more sophisticated metrics like Root Mean Square Error and measurement uncertainty (see section 3). 


### 2.2. Classification of low-cost sensors


For each model of SSys, the OEM manufacturer was identified and the manufacturer of the SSys as well. Overall, we found *`r n_model_count`* models of LCS including both OEMs *(`r n_OEM_count`)* and SSys *(`r n_SS_count`)* manufactured by *`r n_manufacturer_count`* manufacturers (*`r n_DB_manufacturers_OEM`* OEM and *`r n_DB_manufacturers_SS`* SSys).
In addition, *`r n_projects_count`* projects about the evaluation of OEMs and/or SSys reporting quantitative comparison of LCS data and reference measurements were identified. They include the Air Quality Egg, Air Quality Station, AirCasting [@aq-spec_air_2015; @mukherjee_assessing_2017; @feinberg_long-term_2018; @borghi_precision_2018], Carnegie Mellon[@feinberg_long-term_2018; @zikova_estimating_2017], CitiSense[@williams_sensor_2014] Cairsense[@jiao_community_2016], Developer Kit [@aq-spec_air_2015], HKEPD/14-02771 [@sun_development_2016], making-sense.eu [@mijling_practical_2017], communitysensing.org [@vaughn_characterization_2010], MacPoll.eu [@spinelle_field_2015], OpenSense II [@mueller_design_2017; @bigi_performance_2018], Proof of Concept AirSensEUR[@karagulian_calibration_2019], SNAQ Heathrow [@mead_use_2013; @popoola_development_2016]). 
Out of the *`r n_DB_length`* r Records collected from literature, we identified *`r n_DB_length_records_living`* Records (*`r n_DB_length_records_living_OEM`* OEM and *`r n_DB_length_records_living_SS`* SSys) from *`r n_DB_length_living`* **alive** sensors (*`r n_DB_length_living_OEM`* OEM and *`r n_DB_length_living_SS`* SSys) and *`r n_DB_length_records_non_living`* Records (*`r n_DB_length_records_non_living_OEM`* OEM and *`r n_DB_length_records_non_living_SS`* SS ) from *`r n_DB_length_non_living`*  “non active” (or discontinued) LCSs (*`r n_DB_length_non_living_OEM`* OEM and *`r n_DB_length_non_living_SS`* SSys).
“Low-cost” refers to the price of purchase of LCS [@lewis_low-cost_2018] compared to the purchase and operating cost of reference analysers[@mead_use_2013] hat can easily exhibit a 10 fold ratio for the monitoring of regulated inorganic pollutants and particulate matter. More recently, ultra-affordable OEMs are starting to appear on the market for PM monitoring. [@laquai_particle_2017; @budde_suitability_2018; @badura_optical_2018]. For the detection of $PM_{2.5}$, some of these sensors are starting achieving performances comparable  to low-cost OEMs manufactured in the Western world.  Many of them are designed to be integrated in Internet of Things (IoT) networks of interconnected devices. Currently, for PM detection it is possible to purchase optical sensors that cost between a few tens and a few hundreds of euro. Those devices are manufactured in emerging economies such as the Republic of China and the Republic of Korea [@the_world_air_quality_index_sensing_2019].Some of these LCS can achieve similar performance to more expensive OEMs [@aq-spec_air_2015; @williams_air_2014; @williams_deliberating_2019; @williams_evaluation_2014; @williams_sensor_2014; @vaughn_characterization_2010; @fishbain_evaluation_2017; @holstius_field_2014].
The data treatment of LCSs can be classified in two distinct categories:

1)  Processing of LCS data performed by an “open source” software tuned according to several calibration parameters and environmental conditions. All data treatments from data acquisition until the conversion to pollutant concentration levels is known to the user. There were identified identified *`r open_source`* Records made of *`r open_source_OEM`*  OEMs and *`r open_source_SS`* SSys using such an open source software for data management. These *`r open_source`* Records came from *`r n_open_source`* unique LCSs. Usually, outputs from these LCS are already in the same measurement units as the reference measurements. In this category, LCS devices are generally connected to a custom-made data acquisition system to acquire LCS raw data. Generally, users are expected to set a calibration function in order to convert LCS raw data to validate against reference measurements. 


2)  LCS with calibration algorithms whose data treatment is unknown and without the possibility to change any parameter have been identified as “black boxes”. This is due to  the impossibility for the user to accurately know the whole chain of data treatment. There were identified *`r black_box`* Records made up of *`r black_box_OEM`* and *`r black_box_SS`* SSys not using an open source software for data treatment. These *`r black_box`* Records came from *`r n_open_source`* unique LCSs. In most cases, these SSys are previously calibrated against a reference system or, the calibration parameters can be remotely adjusted by the manufacturer. Finally, we should point out that some LCSs used for the detection of Particulate Matter (such as the OPC-N2; OPC-N3 by Alphasense and the PMS series from Plantower) could be used as open source devices if users compute PM mass concentration using the available counts per bins. However, these PM sensors are mostly used as a “black box” with mass concentration computed by unknown algorithms developed by manufacturers. 


Clear definitions and examples of the principle of operations used by the different types of sensor (electrochemical, metal oxides, optical particulate counter, optical sensors) are reported in a recent work by WMO [@lewis_low-cost_2018]. This work also describes several limitations of each type of sensor such as, interference by meteorological parameters, cross-sensitivities to other pollutants, drifts and aging effect. To date, there is a larger number of active and commercially available LCS (Figure 2). However, while most of the OEMs are open sources, allowing end-users to integrate them into SSys, most of the SSys themselves were found to be “black-box” devices. This represents a limitation when the SSys might need a posteriori calibration other then the one provided by the manufacturer since raw-data are unavailable.
LCS are also classified according to their commercial availability. LCSs were assigned to the “Commercial” category if they could be purchased and operated by any user. LCSs fell under the “Non-commercial” category when it was not possible to find any supplier for purchasing. Typically, this type of LCS are used for research and publication while it is difficult for any user to repeat the same sensor setup. 
Figure 1. shows the number of LCSs, either OEM or SSys, that were found still active or discontinued, with open or “black box” type of data treatment and that are commercially available.

\newline


```{r, Figure 1, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 7, fig.height = 5, fig.cap = "**Figure 1.** Number of sensor models gathered from the literature review. Sensors has ben classified by their type of technology, availability, openness and commerciality."}

# create summary table as data frame (for stacked plot)

  OEM <- c(as.numeric(n_DB_length_living_OEM), 
              as.numeric(n_DB_length_non_living_OEM),
              as.numeric(n_open_source_OEM),
              as.numeric(n_black_box_OEM),
              as.numeric(DB_commercial_OEM),
              as.numeric(DB_non_commercial_OEM))
   
 SS <-  c(as.numeric(n_DB_length_living_SS),
             as.numeric(n_DB_length_non_living_SS),
             as.numeric(n_open_source_SS),
             as.numeric(n_black_box_SS),
             as.numeric(DB_commercial_SS),
             as.numeric(DB_non_commercial_SS))
 

 names_df <- c("active", "non-active", "open source", "black box", "commercial", "non-commercial")  
 
  df_sensors <- as.data.frame(cbind(names_df, OEM, SS))
  
# replace 0 with NA
df_sensors[df_sensors == 0] <- NA

#gather data
summary_df_sensors <- gather(df_sensors, "system", "records", 2:3)

summary_df_sensors$names_df <- as.character(summary_df_sensors$names_df)
summary_df_sensors$system <- as.factor(summary_df_sensors$system)
summary_df_sensors$records <- as.numeric(summary_df_sensors$records)

# display total number of counts for sensors
counts_sensors <- summary_df_sensors %>%
  group_by(names_df) %>%
  summarise(counts = sum(records))

counts_sensors$names_df <- as.factor(counts_sensors$names_df)
counts_sensors$counts <- as.integer (counts_sensors$counts)

# change SS with SSys
levels(summary_df_sensors$system) <- gsub("^SS$","SSys", levels(summary_df_sensors$system))

q <- ggplot(data = summary_df_sensors, 
            aes(names_df, records, fill = system)) +
  theme_bw() +
  geom_bar(stat = "identity", position = position_stack()) +
  scale_x_discrete(limits = names_df) + 
  geom_text(aes(label=records), vjust=1, color="black",
            position = position_stack(0.85), size=4)+
  theme(legend.text = element_text(colour="black", size = 10, face = "bold")) +
  theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1, size=10)) +
  theme(axis.text.x=element_text(size=13,face="bold", colour = "black")) +
  theme(axis.title.x = element_blank()) +                                     
  ylab(expression(paste("number of sensors"))) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=14),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=14, colour="black")) +
  # ggtitle("Low-cost sensors") + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 13, hjust=0.5)) 
q



```


\newline

### 2.3. Recent tests per pollutant and per sensor type 

Table 1 reports the number of ‘Records’, by pollutant and sensor technology, gathered in literature about validation and testing of LCSs against a reference system. Records were collected from laboratory (*`r lab_tests`*) and field tests (*`r field_tests`*). The majority of records refer to commercially available OEMs and SSys, even though a few references about non-commercial LCS were also picked up. 


\newline

```{r Table 1, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}
  
count_pollutant_sensor <- DB

#rename pollutants
levels(count_pollutant_sensor$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^PM2$","PM2.5", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^PM3$","PM2.5", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^PM10-2.5$","PM10", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^PM$","PM2.5", levels(count_pollutant_sensor$pollutant))


# count sensor records by pollutant
count_pollutant_sensor <- count_pollutant_sensor %>%
  group_by(pollutant,
           type_sensor,
           field___lab) %>%
  summarise(counts = length(pollutant),
            # counts_commercial = length(unique(model[which(commercial == "")]) ),
            # counts_NON_commercial = length(unique(model[which(commercial == "NC")]) ),
            # references = paste(unique(id_ref), collapse=","))
            references = paste(unique(new_ref), collapse=", "))


count_pollutant_sensor <- as.data.frame(count_pollutant_sensor)



# count_pollutant_sensor <- count_pollutant_sensor[order(-count_pollutant_sensor$counts),]
count_pollutant_sensor <- count_pollutant_sensor[order(count_pollutant_sensor$pollutant),]
rownames(count_pollutant_sensor) <- NULL
names(count_pollutant_sensor)[names(count_pollutant_sensor)=="counts"] <- "n. records"
names(count_pollutant_sensor)[names(count_pollutant_sensor)=="type_sensor"] <- "type"

# make all references as superscript
# count_pollutant_sensor$references <- paste0("$^{", format(unlist(count_pollutant_sensor$references)),"}$")

levels(count_pollutant_sensor$pollutant) <- gsub("^PM2.5$","$PM_{2.5}$", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^PM10$","$PM_{10}$", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^PM1$","$PM_{1}$", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^NO2$","$NO_{2}$", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^O3$","$O_{3}$", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^CO$","$CO$", levels(count_pollutant_sensor$pollutant))
levels(count_pollutant_sensor$pollutant) <- gsub("^NO$","$NO$", levels(count_pollutant_sensor$pollutant))


Caption <- paste0("**Table 1.** Number of analyzed records for OEMs/Sensor Systems by pollutant and by type of technology.")
set.caption(Caption)
panderOptions("table.emphasize.rownames", FALSE) # remove row.names from the table
panderOptions("table.split.table", Inf) # to avoid to split tables if rows are too long
panderOptions('table.alignment.default', function(df) ifelse(sapply(df, is.numeric), 'right', 'left')) # right alignment for numeric, left otherwise
pander(count_pollutant_sensor, emphasize.strong.cols = 1, missing = "")


```

\newline


For the detection of Particulate Matter, the largest number of LCS tests were carried out for Optical Particle Counters (OPC) with *`r OPC`*  Records followed by Nephelometers with *`r neph`*  Both systems detect particulate matter by measuring the light scattered by particles, with the OPC being able to directly count particles according to their size. On the other hand, nephelometers estimate particle density that is subsequently converted into particle mass. For the detection of gaseous pollutants such as $NO_{2}$, ${NO}$, $CO$ and $O_{3}$,the largest number of tests were performed using electrochemical sensors with 343 Records, followed by Metal Oxides sensors (MOs) with *`r GAS_sensors_counts_electrochemical`* records, followed by metal oxides sensors (MOs) with *`r GAS_sensors_counts_MOS`* Records (see Table 1). Electrochemical sensors are based on a chemical reaction between gases in the air and the working electrode of an electrochemical cell that is dipped into an electrolyte. In a MOs, also named resistive sensor, semiconductor, gases in the air react on the surface of a semiconductor and exchange electrons modifying its conductance.

Table S2 reports the models of OEMs currently used to monitor Particulate Matter and gaseous pollutants ($NO_{2}$, ${NO}$, $CO$ and $O_{3}$) according to their type of technology. On the other hand, models of SSys measuring concentration of particulate matter and gaseous pollutants are reported in Table A3. We want to point out that several SSys can use the same set of OEMs. In very few cases, the same model of SSys was tested using different types of OEMs when performing validation tests [@karagulian_calibration_2019; @gerboles_airsenseur_2015] .

“Living” LCS are devices that are currently available for commercial or research purposes. Considering only the “living” LCSs of Table A2 and Table A3, one may observe that there are less OEMs (24) compared to SSys (65), and therefore different SSys are often based on the same set of OEMs. Additionally, there is a lack of laboratory tests for the OEMs compared to SSys. Among the reviewed ‘Records’ only ~ 11% were attributed to laboratory tests. Therefore, most LCS (~ 90%) were tested in the field where it is not possible to isolate the effect of single pollutants and/or meteorological parameters, since in the ambient air many of these parameters are correlated with each other. Establishing calibration models relying only on field results might lead to cases where parameters that have no effect on the sensor data but that are correlated with other variables having an effect, are taken into account. The performance of such calibration models can be poor when LCSs are used at other sites than the ones used for calibration where the relationship between the parameter used for calibration and the ones having an effect on the response of LCSs may change [@mueller_design_2017; @liu_performance_2019; @esposito_dynamic_2016].
The research covered the period between 2010 and 2019 (year of publication). As shown in Figure 2, only a few preliminary studies about the evaluation of performance of LCSs were published from 2010 to 2014. In 2015, we recorded the highest number of references with 27 different works publishing results about performances of LCS for air quality monitoring. For the test studies carried out by AQ-SPEC [@aq-spec_air_2015], Records were evaluated per model of LCS.


\newline

```{r Figure 2, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 5, fig.height = 4, fig.cap = "**Figure 2.** Number of references per year of publication."}

# unique reference list

DB_references <-DB[DB$reference %in% "AQ-SPEC", c("reference", "year_ref", "model")] %>% 
    filter(!duplicated(.)) 
DB_references$model <- NULL

 DB_references <-rbind(DB_references,
                       DB[-which(DB$reference %in% "AQ-SPEC"), c("reference", "year_ref")] %>% 
    filter(!duplicated(.)))


DB_YEAR <- DB_references %>%
  group_by(year_ref) %>%
  summarise(count_refs = length(reference))

# sum references from 2018 with 2019
# DB_YEAR[DB_YEAR$year_ref == 2018,]$count_refs <- DB_YEAR[DB_YEAR$year_ref == 2019,]$count_refs + DB_YEAR[DB_YEAR$year_ref == 2018,]$count_refs

# DB_YEAR <- DB_YEAR %>%
#   filter(year_ref < 2019)

DB_YEAR$year_ref <- as.factor(DB_YEAR$year_ref)


q <- ggplot(data = DB_YEAR, 
            aes(year_ref, count_refs)) +
  theme_bw() +
  geom_bar(stat = "identity", fill = "grey") +
  # scale_x_discrete(limits = year_ref) + 
  geom_text(aes(label=count_refs, y = 8), vjust=1, color="black", size=5) +
  theme(legend.text = element_text(colour="black", size = 10, face = "bold")) +
  theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1, size=14)) +
  theme(axis.text.x=element_text(size=14,face="bold", colour = "black")) +
  theme(axis.title.x = element_blank()) + 
  guides(fill=FALSE) +   # no legend 
  ylab(expression(paste("number of references"))) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=15),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=15, colour="black")) +
  # ggtitle("trend of references") + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 15, hjust=0.5)) 
q


```

\newline

```{r echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}

# number of site types per different references (only FIELD tests)
DB_sites <- DB %>%
  dplyr::filter(field___lab == "FIELD") %>%
    group_by(site,
             reference) %>%
  summarise(site_bin = 1)

# remove NA row in the "site" column
DB_sites <- DB_sites[!(is.na(DB_sites$site)), ]


DB_sites <- DB_sites %>%
  group_by(site) %>%
  summarise(reference_counts = sum(site_bin, na.rm = T))

# sum "urban" with "suburban"
DB_sites[DB_sites$site == "urban",]$reference_counts <- DB_sites[DB_sites$site == "urban",]$reference_counts + DB_sites[DB_sites$site == "suburban",]$reference_counts

# sum "rural" with "semirural"
DB_sites[DB_sites$site == "rural",]$reference_counts <- DB_sites[DB_sites$site == "rural",]$reference_counts + DB_sites[DB_sites$site == "semi-rural",]$reference_counts

# n. references with urban sites
n_refs_URBAN <- as.numeric(DB_sites[DB_sites$site == "urban", 2])
n_refs_RURAL <- as.numeric(DB_sites[DB_sites$site == "rural", 2])
n_refs_TRAFFIC <- as.numeric(DB_sites[DB_sites$site == "traffic", 2])

# counts records and models based on their averaging time 
DB_AVG_time <- DB %>%
  group_by(time_avg,
           model) %>%
  summarize(time_counts = length(time_avg)) 

DB_AVG_time <- DB_AVG_time %>%
  mutate(model_bin = 1)

DB_AVG_time <- DB_AVG_time %>%
  group_by(time_avg) %>%
  summarise(time_counts = sum(time_counts),
            n_models = sum(model_bin))

# only select records from 5min, 1h, 24h and 1 min AVG time

DB_AVG_time <- DB_AVG_time %>%
  filter(time_avg %in% c("1 min", "5 min", "24 hour", "1 hour"))
DB_AVG_time <- DB_AVG_time[order(-DB_AVG_time$time_counts),]

names(DB_AVG_time) <- c("Averaging time", "n. records", "n. OEMs & SS")

hourly_records <- DB_AVG_time$`n. records`[1]
hourly_models <- DB_AVG_time$`n. OEMs & SS`[1]

records_24h <- DB_AVG_time$`n. records`[3]
models_24h <- DB_AVG_time$`n. OEMs & SS`[3]

```

\newline
  

Overall, *`r n_refs_URBAN`* references reporting field tests with LCSs co-located at urban sites were found, as well as *`r n_refs_RURAL`* references for rural sites, and *`r n_refs_TRAFFIC`* references for traffic sites. Most of the laboratory and field tests reported hourly data (*`r hourly_records`* Records for *`r hourly_models`*  models of LCSs). We also found *`r records_24h`* Records for *`r models_24h`* LCSs using daily data. Therefore, hourly data were considered statistically more significant.

### 3. Method of evaluation

The European Union Air Quality Directive [@directive_2008_50_ec] indicates that measurement uncertainty shall be the main indicator used for the evaluation of the data quality objective of air pollution measurement methods [@directive_2008_50_ec].However, the evaluation of this metric is cumbersome [@european_commission_guide_2010] and it is not included in the majority of sensor studies (see Table 2). For the performance criteria used to evaluate air quality modeling applications [@thunis_performance_2012], the set of statistical indicators includes the Root Mean Square Error (RMSE), the bias, the Standard Deviation (SD) and the correlation coefficient (R) among which RMSE is thought to be the most explicative one. The statistical indicators can be better visualised in a target diagram [@spinelle_field_2015].Unfortunately, Table 2 also shows that RMSE is also mainly unavailable in literature. As already mentioned above, integrated indicators like the IPI [@fishbain_evaluation_2017] would breach our objective to use merely quantitative and comparable indicators. Additionally, it is impossible to compute IPIs a posteriori  since time series are mainly not available in literature. 
Therefore, we had to rely on the most common metrics, i. e., the coefficient of determination R2, the slope and intercept of linear regression line between LCS data and reference measurement. $R^{2}$ can be viewed as a measure of goodness of fit (how close evaluation data is to the reference measurements) and the slope of the regression as level of accuracy. $R^{2}$ measures the  strength of the association between two variables but it is insensitive to bias between LCS and reference data, either relative bias (slope different from 1) or absolute bias (intercept different from 0). $R^{2}$ is a partial measure of how much LCS data agree with reference measurements according to a regression model [@barrett_coefficient_1974]. A larger $R^{2}$ reflects an increase in the predictive precision of the regression model. 
An increase of $R^{2}$ may not be the result of an improvement of LCS data quality since $R^{2}$ may increase when the range  of reference measurements increases [@aleixandre_review_2012] or according to the seasonality of sampling reported in different studies. Moreover, since LCS are affected by long time drift and ageing, longer field studies are more likely to report lower $R^{2}$ than shorter one. 

Nearly all published studies report the coefficient of determination ($R^{2}$) between reference and LCS data (see Table 2). Fortunately, the majority of these studies also reports the slope and intercept of the regression line between LCS data and reference measurements that describe the possible bias of LCS data. A few studies also report the Root Mean Square of Error, RMSE [@spinelle_field_2015; @karagulian_calibration_2019; @feinberg_long-term_2018; @mijling_practical_2017; @bigi_performance_2018; @holstius_field_2014; @castell_can_2017; @cross_use_2017; @gillooly_development_2019; @piedrahita_next_2014; @cordero_using_2018; @zheng_field_2018; @liu_performance_2019] which clearly indicates the magnitude of the error in LCS data unit and that is sensitive to extreme values and outliers. Only a few studies report the measurement uncertainty [@karagulian_calibration_2019; @spinelle_field_2015; @williams_evaluation_2014;@laquai_particle_2017; @castell_can_2017; @wei_impact_2018; @zimmerman_machine_2018]. Therefore, for the purpose of this work, we only focused on the analysis of the comparison of laboratory and field tests of LCSs.

\newline

```{r Table 2, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}

# change names FIELD and LAB
levels(DB$field___lab) <- gsub("^FIELD$","Feld Test", levels(DB$field___lab))
levels(DB$field___lab) <- gsub("^LAB$","Laboratory Test", levels(DB$field___lab))

# calibration models
DB_calibration <- DB[!(is.na(DB$r2_calib)), ]
n_DB_calibration <- nrow(DB_calibration)

DB_calibration_LAB <- DB_calibration %>%
  filter(field___lab == "Laboratory Test")
n_DB_calibration_LAB <- nrow(DB_calibration_LAB)

DB_calibration_FIELD <- DB_calibration %>%
  filter(field___lab == "Feld Test")
n_DB_calibration_FIELD <- nrow(DB_calibration_FIELD)

# comparison (regression lines)
DB_comparison <- DB[!(is.na(DB$r2)), ]
n_DB_comparison_r2 <- nrow(DB_comparison)
DB_comparison_LAB <- DB_comparison %>%
  filter(field___lab == "Laboratory Test")
n_DB_comparison_LAB <- nrow(DB_comparison_LAB)

DB_comparison_FIELD <- DB_comparison %>%
  filter(field___lab == "Feld Test")
n_DB_comparison_FIELD <- nrow(DB_comparison_FIELD)

# total number of comparison tests reporting the slope
DB_comparison_slope <- DB[!(is.na(DB$slope)), ]
n_DB_comparison_slope <- nrow(DB_comparison_slope)

# total number of comparison tests reporting the intercept
DB_comparison_intercept <- DB[!(is.na(DB$intercept)), ]
n_DB_comparison_intercept <- nrow(DB_comparison_intercept)


DB_comparison_slope_LAB <- DB_comparison_slope %>%
  filter(field___lab == "Laboratory Test")
n_DB_comparison_slope_LAB <- nrow(DB_comparison_slope_LAB)

DB_comparison_intercept_LAB <- DB_comparison_intercept %>%
  filter(field___lab == "Laboratory Test")
n_DB_comparison_intercept_LAB <- nrow(DB_comparison_intercept_LAB)

DB_comparison_slope_FIELD <- DB_comparison_slope %>%
  filter(field___lab == "Feld Test")
n_DB_comparison_slope_FIELD <- nrow(DB_comparison_slope_FIELD)

DB_comparison_intercept_FIELD <- DB_comparison_intercept %>%
  filter(field___lab == "Feld Test")
n_DB_comparison_intercept_FIELD <- nrow(DB_comparison_intercept_FIELD)



# total number of comparison tests reporting the RMSE
DB_comparison_RMSE <- DB[!(is.na(DB$rmse)), ]
n_DB_comparison_RMSE <- nrow(DB_comparison_RMSE)

DB_comparison_RMSE_LAB <- DB_comparison_RMSE %>%
  filter(field___lab == "Laboratory Test")
n_DB_comparison_RMSE_LAB <- nrow(DB_comparison_RMSE_LAB)

DB_comparison_RMSE_FIELD <- DB_comparison_RMSE %>%
  filter(field___lab == "Feld Test")
n_DB_comparison_RMSE_FIELD <- nrow(DB_comparison_RMSE_FIELD)


# total number of comparison tests reporting the Uncertainty (U)
DB_comparison_U <- DB[!(is.na(DB$u)), ]
n_DB_comparison_U <- nrow(DB_comparison_U)

DB_comparison_U_LAB <- DB_comparison_U %>%
  filter(field___lab == "Laboratory Test")
n_DB_comparison_U_LAB <- nrow(DB_comparison_U_LAB)

DB_comparison_U_FIELD <- DB_comparison_U %>%
  filter(field___lab == "Feld Test")
n_DB_comparison_U_FIELD <- nrow(DB_comparison_U_FIELD)

n_FIELD_tests <- c(as.numeric(field_tests),
                   as.numeric(n_DB_calibration_FIELD),
                   as.numeric(n_DB_comparison_FIELD),
                   as.numeric(n_DB_comparison_slope_FIELD),
                   as.numeric(n_DB_comparison_intercept_FIELD),
                   as.numeric(n_DB_comparison_RMSE_FIELD),
                   as.numeric(n_DB_comparison_U_FIELD))

n_LAB_tests <- c(as.numeric(lab_tests),
                   as.numeric(n_DB_calibration_LAB),
                   as.numeric(n_DB_comparison_LAB),
                   as.numeric(n_DB_comparison_slope_LAB),
                   as.numeric(n_DB_comparison_intercept_LAB),
                   as.numeric(n_DB_comparison_RMSE_LAB),
                   as.numeric(n_DB_comparison_U_LAB))


# remove NA values
DB_prices <- DB[!(is.na(DB$price)), ]
# DB_prices <- DB_prices %>%
#   filter(price > 0)

count_DB_prices <- DB_prices[!duplicated(DB_prices[c("model")]),]
n_price <- nrow(count_DB_prices)

df_metrics <- cbind(n_FIELD_tests,
                    n_LAB_tests)
# df_metrics <- rbind(df_metrics, n_price)

df_metrics <- as.data.frame(df_metrics)

rownames(df_metrics) <- c("", "$R^{2}$ from calibrations", "$R^{2}$ from comparisons", 
                          "slope of reg. line", "intercept", 
                          "RMSE", "Uncertainity (U)")

df_metrics <- data.frame(names = row.names(df_metrics), df_metrics)

rownames(df_metrics) <- NULL

colnames(df_metrics) <- c("metrics", "n. Field Tests ", "n. Laboratory Tests")

levels(df_metrics$metrics) <- gsub("^R2 calibration$","$R^{2} calibration$", levels(df_metrics$metrics))
levels(df_metrics$metrics) <- gsub("^R2 comparison$","$R^{2} comparison$", levels(df_metrics$metrics))

Caption <- paste0("**Table 2.** Number of records gathered by metric used in this work.")
set.caption(Caption)
panderOptions("table.emphasize.rownames", FALSE) # remove row.names from the table
panderOptions("table.split.table", Inf) # to avoid to split tables if rows are too long
panderOptions('table.alignment.default', function(df) ifelse(sapply(df, is.numeric), 'right', 'left')) # right alignment for numeric, left otherwise
pander(df_metrics, emphasize.strong.cols = 1, missing = "")


```


\newline

```{r, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}

n_calibration_model <- DB %>%
  group_by(pollutant,
           model_type_calibration) %>%
  summarise(counts = length(model_type_calibration),
#           references = paste(unique(id_ref), collapse=","))
            references = paste(unique(new_ref), collapse=", "),
            median_r2_calib = format(median(r2_calib, na.rm = T), digits = 2),  
           median_r2 = format(median(r2, na.rm = T), digits = 2))



# make all references as superscript
# n_calibration_model$references <- paste0("$^{", format(unlist(n_calibration_model$references)),"}$")

n_calibration_model <- n_calibration_model[!is.na(n_calibration_model$model_type_calibration),]
names(n_calibration_model)[names(n_calibration_model)=="counts"] <- "n. records"
names(n_calibration_model)[names(n_calibration_model)=="model_type_calibration"] <- "calibration model"
total_n_calibration_records <- sum(n_calibration_model$`n. records`, na.rm = T)

```


## 4.Evaluation of sensor data quality


### 4.1 Calibration of sensors

The method used for the calibration of LCS is generally considered confidential information by the majority of LCS manufacturers. In fact, little information can be found about the calibration of LCS that fall under the category “black box” compared to the ones that fall under the category “Open source”. In fact, several studies can be found about the calibration of “Open source” LCSs, both with laboratory and field tests. Calibration consists of setting a mathematical model describing the relationship between LCS data and reference measurements. However, most of the calibrations were carried out during field tests, while only a limited number of laboratory experiments were found available. 

Out of a total of *`r n_DB_length`* records in the database, *`r total_n_calibration_records`* Records (25%) included information about LCS calibration giving details of used statistical or deterministic models (see Table 3). However, among these *`r n_DB_length`* Records with details on calibration method, about 20 % do not report $R^{2}$, that is the principal metrics used for LCS performance evaluation. This is typically the case for Artificial Neural Networks, Random Forest  and support vector regression calibration methods (see below) and it explains why the number of $R^{2}$ found for calibration in Table 2 is lower than *`r total_n_calibration_records`*.

The linear model and the multi-linear regression model (MLR) which includes the use of covariates to improve the quality of the calibration are the most widely used techniques to calibrate the LCS data against a reference measurement. Other calibration approaches used the exponential, logarithmic, quadratic, Kohler theory of particles growing factor and few types of supervised learning techniques including Artificial Neural Networks (ANN), Random Forest (RF: ), Support Vector Machine (SVM: ) and support vector regression (SVR). Most of MLR models used covariates such as meteorological parameters (temperature and relative humidity) and cross-sensitivities from gaseous interferent such as nitric dioxide ($NO_{2}$), Nitric Monoxide ($NO$) and Ozone ($O_{3}$)in order to improve LCS calibration. Rarely, LCS data time-drift was included into the list of calibration covariates [@jiao_community_2016; @piedrahita_next_2014].

\newline

```{r Table 3, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}

Caption <- paste0("**Table 3.** Types of calibration models used for the calibration of sensors at different time resolutions (ANN: artificial neural network, exp: exponential; log: logarithmic; MLR: multilinear regression; quad: quadratic; RF: random forest; SVM: support vector machine; SVR: support vector regression)")
set.caption(Caption)
panderOptions("table.emphasize.rownames", FALSE) # remove row.names from the table
panderOptions("table.split.table", Inf) # to avoid to split tables if rows are too long
panderOptions('table.alignment.default', function(df) ifelse(sapply(df, is.numeric), 'right', 'left')) # right alignment for numeric, left otherwise

pander(n_calibration_model, emphasize.strong.cols = 1, missing = "")

```

\newline

When $R^{2}$ is both available for calibration and comparison, the median of $R^{2}$ is higher for calibration (mean of $R^{2}$ = 0.70) than for comparison (median of $R^{2}$ = 0.58). This is an expected results since it is easier to fit a model on a short calibration dataset than correctly forecast LCSs data using the calibration model at later dates. For gaseous LCSs, calibration using a linear model gives the worth $R^{2}$ of field comparison. Linear calibration should be avoided for gas LCSs.
For ${CO}$ and ${CO}$, the calibration method giving the highest $R^{2}$² (about 0.90) is the MLR method using temperature or relative humidity as covariates. The use of supervised learning techniques (ANN, RF or SVR) did not improve performance for CO or gave similar results than MLR for NO. This is in slight contradiction with other studies about the performance of supervised techniques [@jovasevic-stojanovic_use_2015; @de_vito_calibrating_2018]. In the majority of cases, these tested LCSs consisted of electrochemical sensors. 
For $NO_{2}$, supervised learning techniques (ANN, RF, SVM or SVR) performed slightly better than MLRs looking at the $R^{2}$ of comparison tests in field, except for SVR which is in slight contradiction with other studies [@de_vito_calibrating_2018]. However, the number of records is much higher MLR than for supervised learning techniques. MLR was applied to both MOs sensor and electrochemical sensors which resulted in scattered R² when looking at individual studies. Additionally, supervised learning techniques may be more sensitive to re-location than MLR [@esposito_dynamic_2016].  
For $O_{3}$, ANN and MLR calibration gave similar $R^{2}$ of comparison (median value about 0.90). As for $NO_{2}$, the higher number of studies makes the $R^{2}$ of the MLR method more significant than the one of ANN.

For PM, the $R^{2}$ for comparison tests are very scattered over the calibration methods. Some high values ($R^{2}$ higher than 0.95) were reported for studies using a linear calibration while MLR did not perform well ($R^{2}$ < 0.5). This results are misleading, since the good results with linear calibration are generally obtained by discarding LSCs data obtained with relative humidity exceeding a threshold between 70 and 80% for which humidity is responsible for particle growing [@crilley_evaluation_2018; @di_antonio_developing_2018]. This effect is more important for $PM_{10}$ than for $PM_{1}$ and $PM_{2.5}$. Other studies did not discard high relative humidity. They took into consideration the particle growing factor either on mass concentration with an exponential calibration model ([@dacunto_determining_2015; @austin_laboratory_2015; @kelly_ambient_2017]) with a median $R^{2}$ of 98 or using the Kölher theory on PM mass concentration [@han_feasibility_2017] or directly for the particles beans of each OPC bin [100] leading to $R^{2}$ about 0.80.

Figure 3 shows a summary of all mean $R^{2}$ obtained from the calibration of SSys against reference measurements. Results were grouped by model of SSys and averaged per reference work. For the same SSys we can observe $R^{2}$ ranging between 0.40 and 1.00. This shows the variability of the performance of SSys depending on the type of calibration, type of testing sites and seasonality and making it difficult to compare the results of different studies. 
Calibration of LSC against a reference analyser was found to be carried out using different averaging time. Test results with hourly data are presented in Figure A1 and test results with minute data time are given in Figure A2. 
The best performance, according to the time average availability in literature and tests in laboratory and/or in the field, were found for:


* For the measurement of $PM_{2.5}$, $R^{2}$ ~ 1 close to 1 were found for hourly data of **PMS1003** by **Plantower** [@kelly_ambient_2017] and for the **PMS3003**, **Dylos DC1100 PRO** and **DC1700** by **Dylos** for minute data [@zheng_field_2018; @aq-spec_air_2015; @steinle_personal_2015].Strangely, higher $R^{2}$ were reported for the Plantower and Dylos when calibrated with minute data than for hourly data. The **OPC-N2** by **AlphaSense** [@aq-spec_air_2015] reported values of $R^{2}$ falling within the range of 0.7 - 1.0. The same OEM sensor OPC-N2, reported values of $R^{2}$ just above 0.7 when measuing $PM_{1}$ while it did not show a good performance when measuring $PM_{10}$ [@aq-spec_air_2015].We need to stress out that optical sensors, such as OPCs and nephelometers, are somewhat limited to fight gravity when detecting coarse particulate matter because of the low-efficiency of the sampling system. Most of the regression models used for the calibration of LCSs used hourly data. 
* For the calibration of  $O_{3}$ LCS the highest values of $R^{2}$ for hourly data was reported for **FIS SP-61** by **FIS** and **O3-3E1F** by **CityTechnology** (Figure A1) [@spinelle_evaluation_2016]. On the other hand, for minute data, values of $R^{2}$ close to 1 were found for **AirSensEUR (v.2)** by **LiberaIntentio** [@karagulian_calibration_2019] as well as for the **S-500** by **Aeroqual** [@aq-spec_air_2015] (Figure A2). AirSensEUR used a built-in AlphaSense **OX-A431** OEM. We want to point out that, most of the MLR models used for calibrating $O_{3}$ LCSs needs $NO_{2}$ to correct for the strong $NO_{2}$ cross-sensitivity. 
* For the calibration of $NO_{2}$ LCSs, we found values of $R^{2}$ for hourly data within the range 0.7 - 1.0 for the *NO2-B42F**  (by Alphasense [@wei_impact_2018]), *AirSensEUR (v.2)** by LiberaIntentio [@karagulian_calibration_2019] and for the minute values **MAS** [@sun_development_2016] (see Figure 3). The $NO_{2} measurement of the AirSensEUR (v.2) are carried out using the NO2-B43F OEM by AlphaSense.
* Most of the Records about the calibration of $CO$ LCSs showed high values of $R^{2}$. As shown in Figure A1, the OEMs **CO 3E300** by **City Technology** [@gerboles_airsenseur_2015] and **CO-B4** by **Alphasense** [@wei_impact_2018] reported $R^{2}$ ~ 1 for hourly data. High values of $R^{2}$ were also reported for the SSys **AirSensEUR (v.2)** when calibrating CO minute data [@karagulian_calibration_2019] (Figure A2). Other LCSs reporting values of $R^{2}$ within the range 0.7 - 1.0 for hourly data consisted of the **MICS-4515** by  and **SGX Sensortech** [@piedrahita_next_2014], the **Smart Citizen Kit** by **Acrobotic** [@aq-spec_air_2015] and the **RAMP** [@zimmerman_machine_2018] 

\newline

```{r Figure 3, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 14, fig.height = 13, fig.cap = "**Figure 3.** Mean $R^2$ for obtained from the calibration of sensor systems against reference measurements."}

DB_calibration <- DB[!(is.na(DB$r2_calib)), ]

# summarize by reference
DB_calibration <- DB_calibration %>%
  group_by(new_ref_author,
           model) %>%
   filter(OEM_system == "SS") %>%
  summarise(mean_r2_calib = mean(r2_calib, na.rm = T))

DB_calibration <- DB_calibration %>%
  filter(mean_r2_calib > 0.25)

# create a new referecne with number (ID) of the reference and first author name
DB_calibration$id_ref_new <- NULL
# DB_calibration$id_ref_new <- paste0("[", DB_calibration$id_ref, "]")
# DB_calibration$id_ref_new <- DB_calibration$id_ref
DB_calibration$id_ref_new <- DB_calibration$new_ref_author

#======== Calibration plots for all pollutants (R2)


plot <- ggplot(DB_calibration, aes(mean_r2_calib, model)) +
  theme_bw() +
  theme(panel.grid.major.y = element_line(colour="grey", size = 1, linetype="dashed"),
        panel.grid.major.x = element_line(colour="grey", size = 1)) +
  geom_point(alpha=1, color="black", size = 4) + 
 # facet_grid(model ~ .) + 
  geom_line(size = 2) +
 # geom_text(aes(label=id_ref),hjust=0.5, vjust=0, angle = 20, nudge_y = 0.4, size = 4, col = "black") +
 # geom_text_repel(aes(label=id_ref_new), size = 5, show.legend = FALSE) +
  geom_text_repel(aes(label=new_ref_author), size = 6.5, show.legend = FALSE) +
  ylab("Sensor System") +
  scale_y_discrete(expand=c(0.01, 0.6)) +
  xlim(0.25, 1.02) +
  xlab(expression(paste(R^2),size=40)) + 
  geom_vline(xintercept=1.0, linetype="dashed", color = "red", size = 1.2) +
  theme(axis.title.y = element_text(face="bold", colour="black", size=22, margin = margin(t = 0, r = 20, b = 0, l = 0)),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=22, colour = "black")) +
   theme(axis.title.x = element_text(colour="black", size=22),
        axis.text.x  = element_text(angle=0, vjust=0.5, hjust = 0.5, size=22, colour = "black")) +
  # ggtitle(expression(paste("Mean value of ", R^2, " from the CALIBRATION of sensor systems"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 18, hjust = 0.5)) 
plot


```

\newline

### 4.2 Comparison of calibrated low-cost sensors with reference measurements

In this review, Records describing the comparison of LCS data with reference measurements came from “open source” and “black box” LCSs. As for the Records collected from the calibration of LCS, comparison with reference system was carried out at different time-resolutions. Here we only report comparisons of hourly data with *`r AVG_comp_SS`* and *`r AVG_comp_OEM`*  Records from SSys and OEMs, respectively. In Figure 4 we have reported the $R^{2}$ values for SSys per reference averaged for all pollutants measured by each SSys. One can observe scattered of $R^{2}$ for a few SSys that are tested in several references in different locations, seasons and durations. 

Figure A3 and Figure A4 show the distribution of $R^{2}$ of LCSs hourly and minute values measuring $PM_{2.5}$, $PM_{10}$, $PM_{1}$, $O_{3}$, $NO_{2}$ and $CO$ against reference measurements:

* For the SSys,  **PA-II** by **PurpleAir** [@aq-spec_air_2015] and **PATS+** by **Belkley Air** [@pillarisetti_small_2017] showed the highest $R^{2}$ with values between 0.8 and 1.0. Other LCSs with $R^{2}$ values ranging between 0.7-1.0 included the **PMS-SYS-1** by **Shinyei**, the **Dylos 1100 PRO** by **Dylos**, the **MicroPEM** by **RTI**, the **AirNUT** by **Moji China ** the **Egg (2018)** by **Air Quality Egg**, the **AQT410 v.1.15** by **Vaisala**, the **AirVeraCity** by **AirVeraCity**, the **NPM2** by MetOne [@crunaire_1er_2018] and, the **Air Quality Station** by **AS LUNG** [@aq-spec_air_2015]. We need to point out that the performance of LCSs measuring PM10, on average, was very poor.
* For the hourly PM measurements of OEMs (Figure A5), the **OPC-N2**, **OPC-N3** [@aq-spec_air_2015; @mukherjee_assessing_2017; @feinberg_long-term_2018; @crilley_evaluation_2018; @badura_optical_2018] the **SDS011** by **Nova Fitness** [@badura_optical_2018] showed $R^{2}$ values in the range 0.7 - 1.0. For the 24-hour PM measurements of OEMs (Figure A6), we found $R^{2}$ within the range 0.7 - 1.0 for the **OPC-N2**, **OPC-N3** [@aq-spec_air_2015].
* For the 24-hour PM measurements of SSys (Figure A7), **PA-II**, [@aq-spec_air_2015] **AirQUINO** by **CNR** [@cavaliere_development_2018] showed $R^{2}$ values close to 1 for $PM_{2.5}$.
* For gaseous pollutants, high $R^{2}$ ranging between 0.7 and 1.0 were found for the following multipollutant LCSs: **AirSensEUR (v.2)** by **LiberaIntentio** [@karagulian_calibration_2019], the **AirVeraCity**, the **AQY** and **S-500** by Aeroqual and the **SNAQ** of the University of Cambridge (Figure A3).
* For the hourly gaseous measurements (Figure A5), we found very few OEMs with $R^{2}$ in the range 0.7 - 1.0. These included the **CairClip O3/NO2** by **CairPol** [@spinelle_field_2015; @williams_sensor_2014; @duvall_performance_2016; @feinberg_long-term_2018], the **Aeroqual Series 500 (and SM50)** [@feinberg_long-term_2018], the **O3-3E1F** by **CityTechnology** [@spinelle_field_2015; @spinelle_performance_2015; @feinberg_long-term_2018; @gerboles_airsenseur_2015] and the **NO2-B43F** by **Alphasense** [@zimmerman_machine_2018; @sun_development_2017]. On the other hand, we found very few Records for SSys using daily data. Additionally, one can notice, comparing Figure A4 and Figure A5, that the performance of OEMs is generally enhanced when they are integrated inside a SSys, except for $PM_{10}$. 


\newline

```{r Figure 4, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 15, fig.height = 18, fig.cap = "**Figure 4.** Mean $R^2$ for obtained from the comparison of sensor systems against reference measurements."}


DB_comparison <- DB[!(is.na(DB$r2)), ]

# summarize by reference
DB_comparison <- DB_comparison %>%
  group_by(new_ref_author,
           model) %>%
  filter(OEM_system == "SS") %>%
  summarise(mean_r2_comparison = mean(r2, na.rm = T))

DB_comparison <- DB_comparison %>%
  filter(mean_r2_comparison > 0.25)

# create a new referecne with number (ID) of the reference and first author name
DB_comparison$id_ref_new <- NULL
# DB_comparison$id_ref_new <- paste0("[", DB_comparison$id_ref, "]")
DB_comparison$id_ref_new <- DB_comparison$new_ref_author

#======== Calibration plots for all pollutants (R2)


plot <- ggplot(DB_comparison, aes(mean_r2_comparison, model)) +
  theme_bw() +
   theme(panel.grid.major.y = element_line(colour="grey", size = 1, linetype="dashed"),
        panel.grid.major.x = element_line(colour="grey", size = 1)) +
  geom_point(alpha=1, color="black", size = 4) + 
  geom_line(size = 1) +
   geom_text_repel(aes(label=id_ref_new), size = 5.7, show.legend = FALSE) +
  ylab("Sensor Model") +
  scale_y_discrete(expand=c(0.01, 0.6)) +
  xlim(0.25, 1.1) +
  xlab(expression(paste(R^2),size=40)) + 
  geom_vline(xintercept=1.0, linetype="dashed", color = "red", size = 1.5) +
  theme(axis.title.y = element_text(face="bold", colour="black", size=22, margin = margin(t = 0, r = 20, b = 0, l = 0)),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=18, colour = "black")) +
   theme(axis.title.x = element_text(colour="black", size=22),
        axis.text.x  = element_text(angle=0, vjust=0.5, hjust = 0.5, size=22, colour = "black")) +
  # ggtitle(expression(paste("Mean value of ", R^2, " from the COMPARISON of sensor systems with reference measurements"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 15, hjust = 0.5)) 
plot


```


\newline

Figure A8 and Figure A10 show selected SSys that gave a slope of linear regression line of hourly LCS data versus reference measurement from 0.5 to 1.5 and $R^{2}$ higher than 0.7. This selection includes the **AirSensEUR**, the **AirVeracity**, and the **S-500** for gaseous pollutants and the **AirNut**, **AQY v0.5**, **Egg v.2 (PM)**, the **NPM2** for hourly data and AIRQuino, **AQY v0.5**, **Egg v.2 (PM)** and the **PA-I**  for daily data.
Figure A9 and Figure A11 show the same selection as Figure A8 but for OEMs. This list includes the SM50, the **CairClip O3/NO2**, the **S-500** ($O_{3}$, $NO_{2}$), the **NO2-B4F** ($NO_{2}$) for gaseous measurements and the Nova Fitness **SDS011** for $PM_{2.5}$, measurements for hourly data and the **OPC-N2** by Alphasense and the **DataRAM** for daily data. 


## 5 Cost of purchase

For the evaluation of the price of LCSs, we considered all SSys manufactured by commercial companies. Operating costs such as calibration, maintenance, deployment and data treatment are not included in the estimated price of SSys.  
Figure 5 shows the commercial price of LCSs by model and number of measured pollutants and Figure A13 shows the prices for OEMs. There is a large number of SSys measuring one pollutant and only a few ones measuring multiple pollutants. Most OEMs are open source devices (Figure A13). On the other hand, most of the SSys are “black boxes” (Figure 5). Therefore, most of the SSys cannot be easily re-calibrated by users. In fact, most SSys are intended to be ready-to-use air quality monitors. 
In Figure 6 we have shortlisted the best SSys according to their level of agreement with reference systems. Figure 6 includes SSys with hourly and daily data showing $R^{2}$ higher than 0.85 and slopes ranging between 0.8 and 1.2. The Figure shows the price, the number of pollutants being measured, the averaging time and the data openness of the selected SSys. Table 4 reports the SSys shortlisted in Figure 6 with the R² and slope mean values, the list of pollutants being measured, the openness of data, their commercial availability and price.
Among “open source” SSys, we could identify the AirSensEUR by LiberaIntentio and the AIRQuino by the CNR. The remaining shortlisted SSys were identified as “black box”. The **AirSensEUR (v.2)** resulted in a mean $R^{2}$ value of 0.90 and a slope  of 0.94 while the AIRQuino resulted in a mean $R^{2}$ value of 0.91 and a slope of 0.97. We need to point out that, to date, the AIRQuino can be used for the detection of up to five pollutants ($NO_{2}$, ${NO}$, $CO$, $O_{3}$ and $PM$). However, only data for PM were available at the time of this review. 

\newline

```{r, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}


DB_calibration <- DB[!(is.na(DB$r2_calib)), ]

# ...only for Sensor systems (both field and lab tests)
DB_calibration_OEM_SS_1hour <- DB_calibration %>%
 # filter(OEM_system == "OEM") %>%
  filter(time_avg == "1 hour") 

levels(DB_calibration_OEM_SS_1hour$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(DB_calibration_OEM_SS_1hour$pollutant))
levels(DB_calibration_OEM_SS_1hour$pollutant) <- gsub("^PM2$","PM2.5", levels(DB_calibration_OEM_SS_1hour$pollutant))
levels(DB_calibration_OEM_SS_1hour$pollutant) <- gsub("^PM3$","PM2.5", levels(DB_calibration_OEM_SS_1hour$pollutant))
levels(DB_calibration_OEM_SS_1hour$pollutant) <- gsub("^PM10-2.5$","PM10", levels(DB_calibration_OEM_SS_1hour$pollutant))

levels(DB_calibration_OEM_SS_1hour$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")

```

\newline

```{r, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}
DB_comparison <- DB[!(is.na(DB$r2)), ]

total_n_comparison_records <- nrow(DB_comparison)

### Sensor Systems (1 hour)
# ...only for Sensor systems (both field and lab tests)
DB_comparison_SS_1hour <- DB_comparison %>%
  filter(OEM_system == "SS") %>%
  filter(time_avg == "1 hour") %>%
  filter(! pollutant == "PM")

levels(DB_comparison_SS_1hour$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(DB_comparison_SS_1hour$pollutant))
levels(DB_comparison_SS_1hour$pollutant) <- gsub("^PM2$","PM2.5", levels(DB_comparison_SS_1hour$pollutant))
levels(DB_comparison_SS_1hour$pollutant) <- gsub("^PM3$","PM2.5", levels(DB_comparison_SS_1hour$pollutant))
levels(DB_comparison_SS_1hour$pollutant) <- gsub("^PM10-2.5$","PM10", levels(DB_comparison_SS_1hour$pollutant))
levels(DB_comparison_SS_1hour$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")


# OEM (1 hour)
# ...only for Sensor systems (both field and lab tests)
DB_comparison_OEM_1hour <- DB_comparison %>%
  filter(OEM_system == "OEM") %>%
  filter(time_avg == "1 hour") %>%
  filter(! pollutant == "PM")


# OEM (24 hour)
DB_comparison <- DB[!(is.na(DB$r2)), ]

# ...only for Sensor systems (both field and lab tests)
DB_comparison_OEM_24hour <- DB_comparison %>%
  filter(OEM_system == "OEM") %>%
  filter(time_avg == "24 hour") %>%
  filter(! pollutant == "PM")

levels(DB_comparison_OEM_24hour$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(DB_comparison_OEM_24hour$pollutant))
levels(DB_comparison_OEM_24hour$pollutant) <- gsub("^PM2$","PM2.5", levels(DB_comparison_OEM_24hour$pollutant))
levels(DB_comparison_OEM_24hour$pollutant) <- gsub("^PM3$","PM2.5", levels(DB_comparison_OEM_24hour$pollutant))
levels(DB_comparison_OEM_24hour$pollutant) <- gsub("^PM10-2.5$","PM10", levels(DB_comparison_OEM_24hour$pollutant))

levels(DB_comparison_OEM_24hour$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")


# sensor systems (24 hour)

# ...only for Sensor systems (both field and lab tests)
DB_comparison_SS_24hour <- DB_comparison %>%
  filter(OEM_system == "SS") %>%
  filter(time_avg == "24 hour") %>%
  filter(! pollutant == "PM")


```

\newline


```{r, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}

# slope SS (1 hour)

# remove empty lines where slope is null
DB_comparison_SS_1hour <- DB_comparison_SS_1hour[!is.na(DB_comparison_SS_1hour$slope & DB_comparison_SS_1hour$intercept), ]

# filter slopes by units
DB_comparison_SS_1hour <- DB_comparison_SS_1hour %>%
  filter(sensor_result_unit %in% c("µg/m3", "ppb", "ppm", "hppcf", "#", "counts", "mg/m3"))

# invert the value of the slope only if "sensor" is on the y axis

DB_comparison_SS_1hour$new_slope     <- DB_comparison_SS_1hour$slope
DB_comparison_SS_1hour$new_intercept <- DB_comparison_SS_1hour$intercept

Inversion.row <- which(DB_comparison_SS_1hour$y == "Sensor")

if(length(Inversion.row) > 0) {
    DB_comparison_SS_1hour[Inversion.row,"new_slope"] <-  1/DB_comparison_SS_1hour[Inversion.row,"slope"]
    DB_comparison_SS_1hour[Inversion.row,"new_intercept"] <- - DB_comparison_SS_1hour[Inversion.row, "intercept"]/DB_comparison_SS_1hour[Inversion.row,"slope"]
}

# 
# for (i in 1:nrow(DB_comparison_SS_1hour)) {
# if  (DB_comparison_SS_1hour$y[i] == "Sensor") {
#   DB_comparison_SS_1hour$new_slope[i] = 1/DB_comparison_SS_1hour$slope[i]
# } else 
#   DB_comparison_SS_1hour$new_slope[i] = DB_comparison_SS_1hour$slope[i]
# }


# filter sensors with R2 > 0.7 and 0.5< slope< 1.5

DB_comparison_SS_1hour_filtered <- DB_comparison_SS_1hour %>%
  filter(r2 > 0.7 & new_slope > 0.5 & new_slope < 1.5)


# slope OEM (1 hour)

# remove empty lines where slope is null
DB_comparison_OEM_1hour <- DB_comparison_OEM_1hour[!is.na(DB_comparison_OEM_1hour$slope & DB_comparison_OEM_1hour$intercept), ]

# filter slopes by units
DB_comparison_OEM_1hour <- DB_comparison_OEM_1hour %>%
  filter(sensor_result_unit %in% c("µg/m3", "ppb", "ppm", "hppcf", "#", "counts", "mg/m3"))

# invert the value of the slope only if "sensor" is on the y axis

DB_comparison_OEM_1hour$new_slope <- DB_comparison_OEM_1hour$slope
DB_comparison_OEM_1hour$new_intercept <- DB_comparison_OEM_1hour$intercept


Inversion.row <- which(DB_comparison_OEM_1hour$y == "Sensor")

if(length(Inversion.row) > 0) {
    DB_comparison_OEM_1hour[Inversion.row,"new_slope"] <-  1/DB_comparison_OEM_1hour[Inversion.row,"slope"]
    DB_comparison_OEM_1hour[Inversion.row,"new_intercept"] <- - DB_comparison_OEM_1hour[Inversion.row, "intercept"]/DB_comparison_OEM_1hour[Inversion.row,"slope"]
}

# for (i in 1:nrow(DB_comparison_OEM_1hour)) {
# if  (DB_comparison_OEM_1hour$y[i] == "Sensor") {
#   DB_comparison_OEM_1hour$new_slope[i] = 1/DB_comparison_OEM_1hour$slope[i]
# } else DB_comparison_OEM_1hour$new_slope[i] = DB_comparison_OEM_1hour$slope[i]
#   }

# filter sensors with R2 > 0.7 and 0.5< slope< 1.5

DB_comparison_OEM_1hour_filtered <- DB_comparison_OEM_1hour %>%
  filter(r2 > 0.7 & new_slope > 0.5 & new_slope < 1.5)


# slope SS (24 hour)

# remove empty lines where slope is null
DB_comparison_SS_24hour <- DB_comparison_SS_24hour[!is.na(DB_comparison_SS_24hour$slope & DB_comparison_SS_24hour$intercept), ]

# filter slopes by units
DB_comparison_SS_24hour <- DB_comparison_SS_24hour %>%
  filter(sensor_result_unit %in% c("µg/m3", "ppb", "ppm", "hppcf", "#", "counts", "mg/m3"))

# invert the value of the slope only if "sensor" is on the y axis

DB_comparison_SS_24hour$new_slope <- DB_comparison_SS_24hour$slope
DB_comparison_SS_24hour$new_intercept <- DB_comparison_SS_24hour$intercept

Inversion.row <- which(DB_comparison_SS_24hour$y == "Sensor")

if(length(Inversion.row) > 0) {
    DB_comparison_SS_24hour[Inversion.row,"new_slope"] <-  1/DB_comparison_SS_24hour[Inversion.row,"slope"]
    DB_comparison_SS_24hour[Inversion.row,"new_intercept"] <- - DB_comparison_SS_24hour[Inversion.row, "intercept"]/DB_comparison_SS_24hour[Inversion.row,"slope"]
}

# for (i in 1:nrow(DB_comparison_SS_24hour)) {
# if  (DB_comparison_SS_24hour$y[i] == "Sensor") {
#   DB_comparison_SS_24hour$new_slope[i] = 1/DB_comparison_SS_24hour$slope[i]
# } else DB_comparison_SS_24hour$new_slope[i] = DB_comparison_SS_24hour$slope[i]
#   }

# filter sensors with R2 > 0.7 and 0.5< slope< 1.5

DB_comparison_SS_24hour_filtered <- DB_comparison_SS_24hour %>%
  filter(r2 > 0.7 & new_slope > 0.5 & new_slope < 1.5)


# slope OEM (24 hour)

# remove empty lines where slope is null
# DB_comparison_OEM_24hour <- DB_comparison_OEM_24hour[!(is.na(DB_comparison_OEM_24hour$slope)), ]
DB_comparison_OEM_24hour <- DB_comparison_OEM_24hour[!is.na(DB_comparison_OEM_24hour$slope & DB_comparison_OEM_24hour$intercept), ]


# filter slopes by units
DB_comparison_OEM_24hour <- DB_comparison_OEM_24hour %>%
  filter(sensor_result_unit %in% c("µg/m3", "ppb", "ppm", "hppcf", "#", "counts", "mg/m3"))

# invert the value of the slope only if "sensor" is on the y axis

DB_comparison_OEM_24hour$new_slope <- DB_comparison_OEM_24hour$slope
DB_comparison_OEM_24hour$new_intercept <- DB_comparison_OEM_24hour$intercept

Inversion.row <- which(DB_comparison_OEM_24hour$y == "Sensor")

if(length(Inversion.row) > 0) {
    DB_comparison_OEM_24hour[Inversion.row,"new_slope"] <-  1/DB_comparison_OEM_24hour[Inversion.row,"slope"]
    DB_comparison_OEM_24hour[Inversion.row,"new_intercept"] <- - DB_comparison_OEM_24hour[Inversion.row, "intercept"]/DB_comparison_OEM_24hour[Inversion.row,"slope"]
}

# for (i in 1:nrow(DB_comparison_OEM_24hour)) {
# if  (DB_comparison_OEM_24hour$y[i] == "Sensor") {
#   DB_comparison_OEM_24hour$new_slope[i] = 1/DB_comparison_OEM_24hour$slope[i]
# } else DB_comparison_OEM_24hour$new_slope[i] = DB_comparison_OEM_24hour$slope[i]
#   }

# filter sensors with R2 > 0.7 and 0.5< slope< 1.5

DB_comparison_OEM_24hour_filtered <- DB_comparison_OEM_24hour %>%
  filter(r2 > 0.7 & new_slope > 0.5 & new_slope < 1.5)


```


\newline



```{r Figure 5, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 10, fig.height = 11, fig.cap = "**Figure 5.** Prices of SS grouped by model. (Numbers in bold indicates the number of pollutant measured by each sensor. x-axis uses logarithmic scale). Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' & 'updated' and 'non-living' sensors are indicated in black and red color, respectively. $NC$ indicates non commercially available sensor."}


#======== prices of Sensor Systems 


# slect OEMs
DB_SS <- DB %>%
  filter(OEM_system == "SS") 

SS_prices <- DB_SS[!(is.na(DB_SS$price)), ]

# make all new prices in EUR
for (i in 1:nrow(SS_prices)) {
  if  (SS_prices$currency[i] %in% "USD") {
    SS_prices$new_price_EUR[i] = round(0.88*SS_prices$price[i], digits = 0)
  } else SS_prices$new_price_EUR[i] = round(SS_prices$price[i], digits = 0)
}

SS_prices <- SS_prices %>%
  filter(# new_price_EUR < 2500,
         # !living == "N",
          !pollutant == "PM10-2.5",
          !pollutant == "PM2.5-0.5",
          !pollutant == "PM2",
          !pollutant == "PM3",
          new_price_EUR > 0)
# order in alphabetic order
SS_prices <- SS_prices[order(SS_prices$model),]



# number of pollutants measured by each sensor
count_SS_prices <- SS_prices[!duplicated(SS_prices[c("model", "pollutant" )]),]
count_SS_prices <- count_SS_prices %>%
    group_by(model,
             open_close,
             living,
             commercial) %>%
    summarise(counts = length(pollutant))
count_SS_prices <- count_SS_prices[!duplicated(count_SS_prices[c("model")]),]
count_SS_prices <- as.data.frame(count_SS_prices)

# select unique PRICE and POLLUTANT per model of sensor
SS_prices <- SS_prices[!duplicated(SS_prices[c("model", "price")]),]
SS_prices <- SS_prices %>%
  group_by(model) %>%
  summarise(new_price_EUR = mean(new_price_EUR))


price_EUR <- as.data.frame(SS_prices$new_price_EUR)
names(price_EUR) <- "new_price_EUR"

count_SS_prices <- cbind(count_SS_prices, price_EUR)


SS_prices$new_price_EUR = round(SS_prices$new_price_EUR, digits = 0)
# order in alphabetic order
# SS_prices <- SS_prices[order(SS_prices$model),]


color_living <- count_SS_prices %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")


SS_prices <- as.data.frame(SS_prices)

# plot <- ggplot(SS_prices, aes(reorder(model, new_price_EUR), new_price_EUR, fill = new_price_EUR)) +
plot <- ggplot(SS_prices[,c("model", "new_price_EUR")], aes(model, new_price_EUR)) +
  theme_bw() +
  geom_col(stat = "identity", fill = "gray", color='black' ) +
  coord_flip() +
  scale_y_continuous(trans='log10', breaks =c(50, 100, 500, 1000, 10000), limits = c(50, 10000), oob = rescale_none) +
  guides(fill=FALSE) +   # no legend
  # xlab(" ") +
  xlab(expression(paste("model"),size=50)) +
  geom_text(data = count_SS_prices, aes(x = model, y = 11000, label = counts, fontface="plain", colour = factor(open_close)), size = 3, show.legend = FALSE) +
   geom_text(data = count_SS_prices, aes(x = model, y = 5000, label = commercial, fontface="bold", colour = factor(commercial)), size = 3, show.legend = FALSE) +
  scale_color_manual(values =c('black', "black", "red", "blue"),guide="none") +
  theme(axis.title.x=element_text(face="bold", colour="black", size=14),
        axis.text.x  = element_text(angle=0, vjust=1, hjust = 0.5, size=14, colour = "black", face="bold")) +
  ylab(expression(paste("Price (EUR)"),size=30)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=20),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=13, colour = color_living)) +
  # ggtitle(expression(paste("Average prices of reviewed Sensor Systems (SS)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 15, hjust = 0.5)) 

plot


```

\newline

```{r Figure 6, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 10, fig.height = 6, fig.cap = "**Figure 6.** Price of low-cost sensor systems associated to measuremnts performed at different averaging times. Numbers in bold indicate the number of pollutant measured by open source (blue) and black box (black) sensors. Only records with $R^2$ > 0.85 and 0.8 < $slope$ < 1.2 are shown. Names of 'living' & 'updated' and 'non-living' sensors are indicated in black and red color, respectively. $NC$ indicates non commercially available sensor."}

#========Sensor price by model and number of pollutants

# remove NA values
# DB_prices <- DB[!(is.na(DB$price)), ]
# DB_prices <- DB[!(is.na(DB$slope)), ]
# DB_prices <- DB[!(is.na(DB$intercept)), ]

DB_prices <- DB[!is.na(DB$price & DB$slope & DB$intercept), ]

# only 1 hour averaged data
DB_prices <- DB_prices %>%
  filter(time_avg %in% c("1 hour", "24 hour"))


DB_prices$new_slope     <- DB_prices$slope
DB_prices$new_intercept <- DB_prices$intercept

Inversion.row <- which(DB_prices$y == "Sensor")

if(length(Inversion.row) > 0) {
    DB_prices[Inversion.row,"new_slope"] <-  1/DB_prices[Inversion.row,"slope"]
    DB_prices[Inversion.row,"new_intercept"] <- - DB_prices[Inversion.row, "intercept"]/DB_prices[Inversion.row,"slope"]
}


# for (i in 1:nrow(DB_prices)) {
# if  (DB_prices$y[i] == "Sensor") {
#   DB_prices$new_slope[i] = 1/DB_prices$slope[i]
# } 
#   }

# make all new prices in EUR
for (i in 1:nrow(DB_prices)) {
  if  (DB_prices$currency[i] == "USD") {
    DB_prices$new_price_EUR[i] = 0.88*DB_prices$price[i]
  } else DB_prices$new_price_EUR[i] = round(DB_prices$price[i], digits = 0)
}

count_DB_prices <- DB_prices[!duplicated(DB_prices[c("model", "pollutant", "time_avg" )]),]
count_DB_prices <- count_DB_prices %>%
    group_by(model,
             open_close,
             living,
             commercial,
             new_price_EUR,
             time_avg) %>%
    summarise(counts = length(pollutant))

n_price <- count_DB_prices[!is.na(count_DB_prices$new_price_EUR),]


# filter sensors with R2 > 0.7 and 0.5< slope< 1.5
DB_prices <- DB_prices %>%
  filter(r2 > 0.85 & new_slope > 0.8 & new_slope < 1.2)


# only select sensor systems
DB_prices <- DB_prices %>%
  filter(OEM_system == "SS")


# select prices <= 2500 EUR
DB_prices <- DB_prices %>%
  filter(# new_price_EUR < 2500,
         # !living == "N",
          !pollutant == "PM10-2.5",
          !pollutant == "PM2.5-0.5",
          !pollutant == "PM2",
          !pollutant == "PM3",
          new_price_EUR > 0)
# order in alphabetic order
DB_prices <- DB_prices[order(DB_prices$model),]

all_DB_prices <- DB_prices


# select unique PRICE and POLLUTANT per model of sensor
DB_prices <- DB_prices[!duplicated(DB_prices[c("model", "price", "time_avg")]),]
count_DB_prices <- count_DB_prices[!duplicated(count_DB_prices[c("model", "time_avg")]),]
count_DB_prices <- as.data.frame(count_DB_prices)

DB_prices <- DB_prices %>%
  left_join(count_DB_prices, c("model" , "time_avg"))

DB_prices <- DB_prices %>%
  select(model,
         open_close.x,
         living.x,
         commercial.x,
         counts,
         new_price_EUR.x,
         time_avg)

color_living <- DB_prices %>%
  group_by(model,
           living.x) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living.x %in% c("Y", "updated"), "black", "red")

  
  # only select sensor systems with  (all possible pollutants)
  names <- count_DB_prices[count_DB_prices$counts >= 0, ]$model
  names <- as.character(names)
  DB_prices <- DB_prices[DB_prices$model %in% names,]
  

  levels(DB_prices$time_avg) <- gsub("^1 hour$","hourly", levels(DB_prices$time_avg))
  levels(DB_prices$time_avg) <- gsub("^24 hour$","daily", levels(DB_prices$time_avg))
  
  models = unique(DB_prices$model)
  List.averaging_hours <- sapply(models, function(i) paste(unique(DB_prices$time_avg[DB_prices$model == i]), collapse = ", "))
  List.averaging_counts <- sapply(models, function(i) max(DB_prices$counts[DB_prices$model == i], na.rm = T))
  
  # select unique model and price per model of sensor
  DB_prices <- DB_prices[!duplicated(DB_prices[c("model")]),]
  DB_prices$averaging_hours <- List.averaging_hours
  DB_prices$averaging_counts <- List.averaging_counts
  


# plot <- ggplot(DB_prices, aes(reorder(model, new_price_EUR), new_price_EUR)) +
  plot <- ggplot(DB_prices, aes(model, new_price_EUR.x)) +
  theme_bw() +
  geom_bar(stat = "identity", fill = "gray", color='black') +
  guides(fill=FALSE) +   # no legend
  # ylim(0, 2) +
  # facet_grid(time_avg ~ .) +
  theme(strip.text = element_text(size = 15, face="bold")) +
  geom_text(data = DB_prices, aes(reorder(model, new_price_EUR.x), y = 2200, label = List.averaging_counts, fontface="bold", 
                                  colour = factor(open_close.x)), size = 4) +
 geom_text(data = DB_prices, aes(x = model, y = 3000, label = commercial.x, fontface="bold", colour = factor(commercial.x)), size = 4,  show.legend = FALSE) +
 geom_text(data = DB_prices, aes(x = model, y = 4000, label = averaging_hours , fontface="bold"), 
            size = 4, show.legend = FALSE, angle = 90, hjust = -0.1) +
 scale_color_manual(values =c('red', "black", "red", "blue"),guide="none") +
  xlab("model") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=13, colour = color_living, face="bold")) +
  ylab(expression(paste("Price (EUR)"),size=24)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=14),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=12, colour = "black")) +
  # ggtitle(expression(paste("Average prices for short list of low-cost sensor systems"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 15, hjust = 0.5)) 

plot

```


\newline

```{r Table 4, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}

  levels(DB_prices$time_avg) <- gsub("^hourly$","1 hour", levels(DB_prices$time_avg))
  levels(DB_prices$time_avg) <- gsub("^daily$","24 hour", levels(DB_prices$time_avg))

# filter data with AVERAGING TIME  == 1 hour
SS_price_pollutants <- DB_prices %>%
  filter(time_avg == "1 hour")

# identify pollutants measured by each sensor

SS_price_pollutants <- as.data.frame(SS_price_pollutants[,1])
names(SS_price_pollutants) <- "model" 

all_DB_prices_1h <- all_DB_prices %>%
    filter(time_avg == "1 hour")

SS_price_pollutants <- SS_price_pollutants %>%
  left_join(all_DB_prices_1h, c("model"))

# filter sensors with R2 > 0.85 and 0.8< slope< 1.2
SS_price_pollutants <- SS_price_pollutants %>%
    filter(r2 > 0.85 & new_slope > 0.8 & new_slope < 1.2)

# make all new prices in EUR
for (i in 1:nrow(SS_price_pollutants)) {
  if  (SS_price_pollutants$currency[i] == "USD") {
    SS_price_pollutants$new_price_EUR[i] = round(0.88*SS_price_pollutants$price[i], digits = 0)
  } else SS_price_pollutants$new_price_EUR[i] = round(SS_price_pollutants$price[i], digits = 0)
}


SS_price_pollutants <- SS_price_pollutants %>%
  select(-price)
# rename "new_price_EUR"" into "price""
names(SS_price_pollutants)[names(SS_price_pollutants)=="new_price_EUR"] <- "price"


means <- SS_price_pollutants %>%
  group_by(model) %>%
  summarise(mean_r2 = format(mean(r2, na.rm = T), digits = 2),
            mean_slope = format(mean(new_slope, na.rm = T), digits = 2),
            mean_intercept = format(mean(abs(new_intercept), na.rm = T), digits = 2))


SS_price_pollutants <- SS_price_pollutants %>%
  group_by(model,
         open_close,
         living,
         commercial,
         pollutant,
         price) %>%
  summarise(mean_r2 = format(mean(r2, na.rm = T), digits = 2),
            mean_slope = format(mean(new_slope, na.rm = T), digits = 2),
            mean_intercept = format(mean(new_intercept, na.rm = T), digits = 2))


SS_price_pollutants <- SS_price_pollutants %>%
  filter(!pollutant == "PM10-2.5",
          !pollutant == "PM2.5-0.5",
          !pollutant == "PM2",
          !pollutant == "PM3")


# select unique model and pollutant per model of sensor
SS_price_pollutants <- SS_price_pollutants[!duplicated(SS_price_pollutants[c("model", "price", "pollutant")]),]

SS_price_pollutants <- SS_price_pollutants %>%
  select(model,
         open_close,
         living,
         commercial,
         pollutant,
         price,
         mean_r2,
         mean_slope,
         mean_intercept)


# change names
levels(SS_price_pollutants$commercial) <- gsub("^NC$","non commercial", levels(SS_price_pollutants$commercial))
levels(SS_price_pollutants$commercial) <- gsub("^$","commercial", levels(SS_price_pollutants$commercial))
levels(SS_price_pollutants$pollutant) <- gsub("^PM2.5$","$PM_{2.5}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^PM10$","$PM_{10}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^PM1$","$PM_{1}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^NO2$","$NO_{2}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^O3$","$O_{3}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^CO$","$CO$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^NO$","$NO$", levels(SS_price_pollutants$pollutant))

#only PM2.5
SS_price_pollutants_PM25 <- SS_price_pollutants %>%
  filter(pollutant == "$PM_{2.5}$")

#only PM10
SS_price_pollutants_PM10 <- SS_price_pollutants %>%
  filter(pollutant == "$PM_{10}$")

#only PM1
SS_price_pollutants_PM1 <- SS_price_pollutants %>%
  filter(pollutant == "$PM_{1}$")

#only NO2
SS_price_pollutants_NO2 <- SS_price_pollutants %>%
  filter(pollutant == "$NO_{2}$")

#only O3
SS_price_pollutants_O3 <- SS_price_pollutants %>%
  filter(pollutant == "$O_{3}$")

#only CO
SS_price_pollutants_CO <- SS_price_pollutants %>%
  filter(pollutant == "$CO$")

#only NO
SS_price_pollutants_NO <- SS_price_pollutants %>%
  filter(pollutant == "$NO$")

AAA <- SS_price_pollutants_PM25 %>%
  full_join(SS_price_pollutants_PM10, c("model")) 

BBB <- AAA %>%
  full_join(SS_price_pollutants_PM1, c("model")) 

CCC <- BBB %>%
  full_join(SS_price_pollutants_NO2, c("model")) 

DDD <- CCC %>%
  full_join(SS_price_pollutants_O3, c("model")) 

EEE <- DDD %>%
  full_join(SS_price_pollutants_CO, c("model")) 

FFF <- EEE %>%
  full_join(SS_price_pollutants_NO, c("model"))


FFF <- as.data.frame(FFF)

FFF <- FFF %>%
  select(-price,
         -price.x,
         -price.x.x,
         -price.x.x.x,
         -price.y,
         -price.y.y,
         -price.y.y.y,
         -open_close,
         - open_close.x,
         - open_close.x.x,
         - open_close.x.x.x,
         - open_close.y,
         - open_close.y.y,
         - open_close.y.y.y,
         - living,
         - living.x,
         - living.x.x,
         - living.x.x.x,
         - living.y,
         - living.y.y,
         - living.y.y.y,
         - commercial,
         - commercial.x,
         - commercial.x.x,
         - commercial.x.x.x,
         - commercial.y,
         - commercial.y.y,
         - commercial.y.y.y,
         - mean_r2,
         - mean_r2.x,
         - mean_r2.x.x,
         - mean_r2.x.x.x,
         - mean_r2.y,
         - mean_r2.y.y,
         - mean_r2.y.y.y,
         - mean_slope,
         - mean_slope.x,
         - mean_slope.x.x,
         - mean_slope.x.x.x,
         - mean_slope.y,
         - mean_slope.y.y,
         - mean_slope.y.y.y,
         - mean_intercept,
         - mean_intercept.x,
         - mean_intercept.x.x,
         - mean_intercept.x.x.x,
         - mean_intercept.y,
         - mean_intercept.y.y,
         - mean_intercept.y.y.y)

# aggregate all pollutants into one column
# df$variable_7 <- apply(df, 1, function(x) paste(x[!is.na(x) & x != "No"], collapse = ", "))
FFF$pollutant <- apply(FFF[2:8], 1, function(x) paste(x[!is.na(x)], collapse = ", "))
FFF <- FFF %>%
  select(model,
         pollutant)

# merge with  price
SS_price_pollutants <- SS_price_pollutants[!duplicated(SS_price_pollutants[c("model", "price", "open_close", "living", "commercial")]),]

FFF <- FFF[order(FFF$model),]
SS_price_pollutants <- cbind(FFF, 
                             means$mean_r2, 
                             means$mean_slope, 
                             means$mean_intercept, 
                             SS_price_pollutants$open_close, 
                             SS_price_pollutants$living, SS_price_pollutants$commercial, 
                             SS_price_pollutants$price)

colnames(SS_price_pollutants) <- c("model", "pollutant", "mean $R^{2}$", "mean slope", "mean intercept", "open/close", "living", "commercial", "price (EUR)")
# sort by price
SS_price_pollutants <- SS_price_pollutants[order(SS_price_pollutants$price),]

rownames(SS_price_pollutants) <- NULL

Caption <- paste0("**Table 4.** Shortlist of sensor systems showing good agreement with reference systems ($R^2$ > 0.85; 0.8 < slope < 1.2) for 1 hour time averaged data.")
set.caption(Caption)
panderOptions("table.emphasize.rownames", FALSE) # remove row.names from the table
panderOptions("table.split.table", Inf) # to avoid to split tables if rows are too long
panderOptions('table.alignment.default', function(df) ifelse(sapply(df, is.numeric), 'right', 'left')) # right alignment for 
pander(SS_price_pollutants, emphasize.strong.cols = 1, missing = "")

```

\newline

Figure 7 shows the relationship between the mean R2 of SSys and the decimal logarithm of the price of LCSs. In Figure 7 only the “living” LCSs are compared. It shows that for OEMs there is not a significant linear relationship between the price of OEMs and the value of R2. Conversely, there is a significant light increase of $R^{2}$ with the logarithm of the price of SSys. The regression equations indicated in Figure 7 shows that R² can increase of 14 ± 6% for a 10-fold increase of the prices of SSys which is a limited increase at high cost. Figure 7 also shows a higher scattering of $R^{2}$ at the low end of the price scale with SSys price lower than 500 euro with more fluctuation of the SSys performance.


\newline


```{r Figure 7, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 7, fig.height = 7, fig.cap = "**Figure 7.** Relation between prices of OEMs/Sensor Systems (SS) and $R^2$ for field test only. Logarithmic scale has been set for both axis. Open source and black box models are indicated with open and full circles, respectively. Names of 'living' and 'non-living' sensors are indicated in black and blue color, respectively. $R^2$ refers to data averaged over 1 hour. Grey shade in the fit plots indicate a pointwise 95% confidence interval on the fitted values."}



#======== prices of OEM vs r2

# remove eventual NULL prices
DB_prices <- DB[!(is.na(DB$price)), ]


levels(DB$field___lab) <- gsub("^FIELD$","Feld Test", levels(DB$field___lab))
levels(DB$field___lab) <- gsub("^LAB$","Laboratory Test", levels(DB$field___lab))

# make all new prices in EUR
for (i in 1:nrow(DB_prices)) {
  if  (DB_prices$currency[i] == "USD") {
    DB_prices$new_price_EUR[i] = round(0.88*DB_prices$price[i], digits = 0)
  } else DB_prices$new_price_EUR[i] = round(DB_prices$price[i], digits = 0)
}



# filter slopes by units
DB_prices <- DB_prices %>%
  filter(sensor_result_unit %in% c("µg/m3", "ppb", "ppm", "#", "mg/m3"),
         new_price_EUR > 0,
         time_avg == "1 hour")

# remove data where r2  is NULL
DB_prices_r2 <- DB_prices[!is.na(DB_prices$r2),]

# select only field test!
DB_prices_r2 <- DB_prices_r2 %>%
  group_by(model,
           OEM_system,
           open_close,
           living) %>%
  filter(!field___lab == "Laboratory Test") %>%
  summarise(mean_r2 = mean(r2),
            mean_price = mean(new_price_EUR))

# rename "updated" with "y" (living)
levels(DB_prices_r2$living) <- gsub("^updated","Y", levels(DB_prices_r2$living))

DB_prices_r2$mean_r2 = round(DB_prices_r2$mean_r2, digits = 2)


## this function includes the intercept~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# my.formula <- y ~ -1 + x (through the origin)
my.formula <- y ~ x


DB_prices_r2_fit <- DB_prices_r2 %>%
  filter(mean_r2 > 0,
         !living == "N",
         !living == "updated")


levels(DB_prices_r2$OEM_system) <- gsub("^SS$","SSys", levels(DB_prices_r2$OEM_system))
levels(DB_prices_r2_fit$OEM_system) <- gsub("^SS$","SSys", levels(DB_prices_r2_fit$OEM_system))

plot <- ggplot(DB_prices_r2, aes(y = mean_r2, x = mean_price)) +
  theme_bw() +
  geom_point(size = 2, aes(shape = open_close, color = open_close), show.legend = FALSE) +
    scale_shape_manual(values=c(16, 1)) +
  # geom_point(size = 2) +
  geom_text_repel(aes(label=model, color = living), size = 2, show.legend = FALSE) +
 scale_color_manual(values=c("black", "blue", "red", "black")) +  # "living", "no-living", "open source", "black box"
 # scale_color_manual(values=c("blue", "black")) +  # "living", "no-living", "open source", "black box"
  scale_x_continuous(trans='log10') +
  scale_y_continuous(trans='log10') +
  # geom_smooth(method = "lm", formula = y ~ -1 + x) +  # force fit through the origin
  facet_grid(OEM_system ~ .) +
  geom_smooth(data = DB_prices_r2_fit, method="lm", formula = my.formula) +  # Add linear regression line
  xlab("price (EUR)") +
  # ylab(" ") +
  ylab(expression(paste("mean ", R^2))) +
  # ylim(c(0,2)) +
  # xlim(c(0,2)) +
  theme(strip.text = element_text(size = 15, face="bold")) +
  theme(strip.text.y = element_text(angle = 0)) +
  theme(axis.title.x = element_text(colour="black", size=15),
        axis.text.x  = element_text(angle=0, vjust=0.5, hjust = 0.5, size=15, colour = "black")) +
  theme(axis.title.y = element_text(colour="black", size=15),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=15, colour = "black")) +
  # ggtitle(expression(paste("Relation between prices of OEMs/Sensor Systems and ", R^2, " (1 hour avg. time)"))) +
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 10, hjust = 0.5)) +
  
  stat_poly_eq(data = DB_prices_r2_fit, formula = my.formula, 
                 aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
                     label.y= 0.3,
                     parse = TRUE) 

plot


model_SS <- lm(log10(DB_prices_r2_fit[DB_prices_r2_fit$OEM_system == "SSys", ]$mean_r2) ~ log10(DB_prices_r2_fit[DB_prices_r2_fit$OEM_system == "SSys", ]$mean_price))


model_OEM <- lm(log10(DB_prices_r2_fit[DB_prices_r2_fit$OEM_system == "OEM", ]$mean_r2) ~ log10(DB_prices_r2_fit[DB_prices_r2_fit$OEM_system == "OEM", ]$mean_price))

```

\newline

## 6. Conclusions

There is little information available in the literature regarding calibration of LCSs. Nevertheless, it was anyhow possible to list the calibration methods giving the highest $R^{2}$ when applied to the results of field tests. For ${CO}$ and ${NO}$ reviewed works showed that the MLR models were the most suitable for calibration. ANN gave the same level of performance than MLR only for NO. For ${NO}_2$ and ${O}_3$, supervised learning models such as, SVR, SVM, (not for ${O}_3$), ANN, and RF followed by MLR models showed to be the most suitable method of calibration. Regarding Particulate Matter, the best results were obtained with linear models when calibrating ${PM}_2.5$. However, these models were applied only to ${PM}_2.5$ with high relative humidity data (> 75-80%) that were discarded. For higher relative humidity, models accounting for the growing of the particulates must be further developed. So far, the calibration using the Khöler theory seems to be the promising method.

A list of SSys with $R^{2}$ and slope close to 1.0 were drawn from the whole database of Records of comparison tests of LCSs data versus reference measurements that indicates the best performance of SSys as shown in Figure 8. In fact, Figure 8 evidences a best selection region for SSys with blue background. The best SSys would be the one which reaches the point with coordinates $R^{2}$ = 1 and slope = 1. Within the blue background region, the following SSys can be found: the **2B Tech. (POM)**, the **PA-II**, the **AirSensEUR (v.1)**, the **PA-I**, the **S-500**, the **AirSensEUR (v.1)**, the **SNAQ**, the **Vaisala AQT410 v.15**, the **MetOne (NM)**, the **Egg (v.2)**, the **AQY v0.5**, the **CairClip O3/NO2**, the **AQMesh v3.0**, the **AQT410 v.11** and the **AirVeraCity**. Additionally, Figure 8 shows that there are more SSys underestimating reference measurements with slopes lower than 1 than SSys overestimating reference measurements.
Analysing the price of SSys and their price, it was found that $R^{2}$ increases of 14 % for a 10-fold increase of the prices of SSys, a limited improvement for a large price increase.
 
\newline


```{r Figure 8, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 8, fig.height = 8, fig.cap = "**Figure 8.** Correspondence between $R^2$ and slope for sensor systems (SS) for 1 hour averaging time. Only sensor models with $mean$ $R^2$ > 0.75 and 0.5 < $mean$ $slope$ < 1.2 are shown. Names of 'living' and 'non-living' sensors are indicated in black and blue color, respectively."}


DB_taylor <- DB


levels(DB$field___lab) <- gsub("^FIELD$","Feld Test", levels(DB$field___lab))
levels(DB$field___lab) <- gsub("^LAB$","Laboratory Test", levels(DB$field___lab))

# select only FIELD TESTS tests
DB_taylor <- DB_taylor %>%
  filter(!field___lab == "Laboratory Test",
          sensor_result_unit %in% c("µg/m3", "ppb", "ppm", "#", "mg/m3"))

# remove records with empty slope
DB_taylor <- DB_taylor[!(is.na(DB_taylor$slope)), ]

# remove records with empty r2
DB_taylor <- DB_taylor[!(is.na(DB_taylor$r2)), ]

DB_taylor$new_slope <- DB_taylor$slope

for (i in 1:nrow(DB_taylor)) {
if  (DB_taylor$y[i] == "Sensor") {
  DB_taylor$new_slope[i] = 1/DB_taylor$slope[i]
} 
  }


# filter sensors with R2 > 0.7 and 0.5 < slope < 1.5
DB_taylor <- DB_taylor %>%
  filter(r2 > 0.75 & new_slope > 0.5 & new_slope < 1.2)

DB_taylor <- DB_taylor %>%
  group_by(model,
         open_close,
         OEM_system,
         living) %>%
  filter(time_avg == "1 hour") %>%
  summarise(mean_r2 = mean(r2),
            mean_slope = mean(new_slope))

# rename "updated" with "y" (living)
levels(DB_taylor$living) <- gsub("^updated","Y", levels(DB_taylor$living))

DB_taylor_SS <- DB_taylor %>%
  filter(OEM_system == "SS")


##########################################################
###### function to shif axis #############################

shift_axis_x <- function(p, x=0){
      g <- ggplotGrob(p)
      dummy <- data.frame(x=x)
      ax <- g[["grobs"]][g$layout$name == "axis-l"][[1]]
      p + annotation_custom(grid::grobTree(ax, vp = grid::viewport(x=1, width = sum(ax$height))), 
                            xmax=x, xmin=x) +
        geom_vline(aes(xintercept=x), data = dummy) +
        theme(axis.text.y = element_blank(), 
              axis.ticks.y=element_blank(),
              # panel.grid.major = element_blank(),
              # panel.grid.minor = element_blank(),
              # panel.background = element_blank(),
              panel.border = element_blank(),
              axis.line.x = element_line(colour = "black"))
}

###########################################################
###########################################################

x <- c(0.5, 1, 1.5)
y <- c(1, 0.75, 1) 
TRIANGLE <- data.frame(x,y)


plot <- ggplot(data = DB_taylor_SS, aes(x = mean_slope, y = mean_r2)) + 
  theme_bw() +
 # theme_classic() +
  geom_point(size = 3, aes(shape = open_close, color = open_close), show.legend = FALSE) +
   geom_polygon(data = TRIANGLE, aes(x=x, y=y), fill = "skyblue2", alpha=0.4) +
    scale_shape_manual(values=c(16, 1)) +
 geom_text_repel(aes(label=model,color = living), size = 4, show.legend = FALSE) +
   scale_color_manual(values=c("black", "blue", "red", "black")) +  # "living", "no-living", "open source", "black box"
#  scale_color_manual(values=c("blue", "black")) +
  xlab("mean slope") +
  xlim(c(0.5,1.5)) +
  ylab(expression(paste("mean ", R^2),size=12)) +
  theme(strip.text = element_text(size = 15, face="bold")) +
  theme(strip.text.y = element_text(angle = 0)) +
  theme(axis.title.x = element_text(colour="black", size=15),
        axis.text.x  = element_text(angle=0, vjust=0.5, hjust = 0.5, size=13, colour = "red")) +
  theme(axis.title.y = element_text(colour="black", size=15),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=13, colour = "red")) +
  # ggtitle(expression(paste("Relation between mean ", R^2, " and mean slope for Sensor Systems (1 hour avg. time)"))) +
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 15, hjust = 0.5)) 

 plot <- shift_axis_x(plot, 1)
 plot


```

\newline

Although this paper gives an exhaustive survey of the independent LCS evaluations, the concept of comparing LCS field tests from different studies can be difficult or results in misleading conclusions. It is difficult because of the lack of uniformity of the metrics representing LCS data quality that are different between studies and difficult to compare. Comparing field tests of LCS may also be misleading since in order to take into consideration the highest number of studies it was necessary to mainly rely on the coefficient of determination $R^{2}$. However,$R^{2}$ is too much dependent on the range of reference measurements, on the duration of test field and on the season and location of the tests making change of $R^{2}$ not completely dependent on LCS data quality or of calibration methods. This shortcoming makes the standardisation of a protocol of evaluation of LCSs at international level of great importance and the results of intercomparison exercise where gathering LCSs are gathered at the same test sites and at the same time greatly desired.


## Appendix A

\newline

```{r Table A1, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}


Caption <- paste0("**Table A1.** Number of analyzed records and sensor models by averaging time.")
set.caption(Caption)
panderOptions("table.emphasize.rownames", FALSE) # remove row.names from the table
panderOptions("table.split.table", Inf) # to avoid to split tables if rows are too long
panderOptions('table.alignment.default', function(df) ifelse(sapply(df, is.numeric), 'right', 'left')) # right alignment for numeric, left otherwise
pander(DB_AVG_time, emphasize.strong.cols = 1, missing = "")


```


\newline


```{r Table  S2A, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}

# # build table reporting and explaining formulas about metrics
# Comparison_metrics <- c("Coefficient of determination", "Slope of linear relation ship", "Intercept of the linear relationship Mi = Slope RMI + Offset", "Root Mean Square Error", "Measurement uncertainty", "Correlation Coefficient")
# 
# Short_name <- c("$R^{2}$", "$slope$", "$Offset$", "$RMSE$", "$U$", "$r$")
# 
# Mathematical_formulas <- c("$$R^2 = 1-\\frac{SS_{RES}}{SS_{TOT}}$$, where SS_RES is the sum of squares of residuals and SS_TOT is the total sum of squares", "", "", "$$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left( {M_i- RM_i} \\right)^2}$$", "$$U = kU_{c}$$", "$$\\frac{ \\frac{1}{n}\\sum_{i=1}^{n}\\left( {M_i - M})({M_i - RM} \\right)}   { \\sqrt{ \\frac{1}{n}\\sum_{i=1}^{n}\\left( {M_i- M} \\right)^2\\frac{1}{n}\\sum_{i=1}^{n}\\left( {RM_i- RM} \\right)  }}$$")
# 
# Characteristics <- c("$R^2$ measures the strentgth of relationship between $M_{i}$ and $RM_{i}$, of the percentage of total                               variance that is explained by a linear relationship", "", "", 
#                      "indicates the magnitude of the error and retains the variable's unit; is sensitive to extreme values and                       to outliers; tends to vary as a function of the standard deviation of the RM",
#                      "", "measures the strength and the direction of a linear relationship between two variables, and receives                       a value between -1 and 1; is independent of the difference in the variance (var) of M and RM, thus if r=1                       and var(M)<var(RM), then variance correction may be required")
# 
# df_Comparison_metrics <- data.frame(Comparison_metrics, Short_name, Mathematical_formulas, Characteristics)
# names(df_Comparison_metrics) <- c("Comparison metrics", "Short name", "Mathematical formulas", "Characteristics")
# 
# Caption <- paste0("**Table S2.** Metrics used for comparing sensor data, $M_{i}$, and reference measurements, $RM_{i}$.")
# set.caption(Caption)
# panderOptions("table.emphasize.rownames", FALSE) # remove row.names from the table
# panderOptions("table.split.table", Inf) # to avoid to split tables if rows are too long
# panderOptions('table.alignment.default', function(df) ifelse(sapply(df, is.numeric), 'right', 'left')) # right alignment for numeric, left otherwise
# pander(df_Comparison_metrics, emphasize.strong.cols = 1, missing = "")
                        

```

\newline


```{r Table A2, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE,  comment=FALSE}

# Model of sensors by for the detection of Particulate Matter. OME/SS indicates Original Equipment Manufacture and Sensor System.

# change prices from USD to EUR
for (i in 1:nrow(DB)) {
  if  (DB$currency[i] == "USD") {
    DB$new_price_EUR[i] = round(0.88*DB$price[i], digits = 0)
  } else DB$new_price_EUR[i] = round(DB$price[i], digits = 0)
}

# models = unique(DB$model[intersect(grep(pattern = "PM", x = DB$pollutant),which(DB$OEM_system == "OEM"))])
models = unique(DB$model[intersect(which(grepl(paste(c("PM","NO2", "O3", "CO", "NO"), collapse = "|"),  x = DB$pollutant)), which(DB$OEM_system == "OEM"))])
List.Pollutants <- sapply(models, function(i) paste(unique(DB$pollutant[DB$model == i]), collapse = ", "))
List.Types      <- sapply(models, function(i) paste(unique(DB$type_sensor[DB$model == i]), collapse = ", "))
List_Refs       <- sapply(models, function(i) paste(unique(DB$new_ref[DB$model == i]), collapse = ", "))
List_Open       <- sapply(models, function(i) paste(unique(DB$open_close[DB$model == i]), collapse = ", "))
List_living     <- sapply(models, function(i) paste(unique(DB$living[DB$model == i]), collapse = ", "))
List_price      <- sapply(models, function(i) if (all(is.na(DB$new_price_EUR[which(DB$model == i)]))) NA else median(DB$price[which(DB$model == i)], na.rm =T) )

sensor_model_OEM = data.frame(model = models,
          List.Pollutants = List.Pollutants,
           List.Types  = List.Types,
          List_Refs = List_Refs,
           List_Open   = List_Open,
           List_living = List_living,
           List_price  = List_price,
           stringsAsFactors = F)

names(sensor_model_OEM) <- c("model", "pollutant", "type", "reference", "open/close", "living", "price")



# OPC and nephelometers
optical <- DB %>%
  group_by(type_sensor,
           model) %>%
  summarise(count = length(type_sensor))

# sort sensors into alphabetic order
sensor_model_OEM <- sensor_model_OEM[order(sensor_model_OEM$model),]


Caption <- paste0("**Table A2.** Model of OEMs by pollutant, type, openness and price.")
set.caption(Caption)
panderOptions("table.emphasize.rownames", FALSE) # remove row.names from the table
panderOptions("table.split.table", Inf) # to avoid to split tables if rows are too long
panderOptions('table.alignment.default', function(df) ifelse(sapply(df, is.numeric), 'right', 'left')) # right alignment for numeric, left otherwise
pander(sensor_model_OEM, emphasize.strong.cols = 1, table.emphasize.rownames = FALSE, missing = "")

```

\newline



```{r Table A3, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE,  comment=FALSE}

# Model of sensors by for the detection of Particulate Matter. OME/SS indicates Original Equipment Manufacture and Sensor System.

models = unique(DB$model[intersect(which(grepl(paste(c("PM","NO2", "O3", "CO", "NO"), collapse = "|"),  x = DB$pollutant)), which(DB$OEM_system == "SS"))])
List.Pollutants <- sapply(models, function(i) paste(unique(DB$pollutant[DB$model == i]), collapse = ", "))
List.Types      <- sapply(models, function(i) paste(unique(DB$type_sensor[DB$model == i]), collapse = ", "))
List_Refs       <- sapply(models, function(i) paste(unique(DB$new_ref[DB$model == i]), collapse = ", "))
List_Open       <- sapply(models, function(i) paste(unique(DB$open_close[DB$model == i]), collapse = ", "))
List_living     <- sapply(models, function(i) paste(unique(DB$living[DB$model == i]), collapse = ", "))
List_price      <- sapply(models, function(i) if (all(is.na(DB$new_price_EUR[which(DB$model == i)]))) NA else median(DB$price[which(DB$model == i)], na.rm =T) )

sensor_model_SS = data.frame(model = models,
           List.Pollutants = List.Pollutants,
           List.Types  = List.Types,
           List_Refs = List_Refs,
           List_Open   = List_Open,
           List_living = List_living,
           List_price  = List_price,
           stringsAsFactors = F)

names(sensor_model_SS) <- c("model", "pollutant", "type", "reference", "open/close", "living", "price")

sensor_model_SS <- sensor_model_SS[order(sensor_model_SS$model),]

Caption <- paste0("**Table A3.** Models of Sensor Systems by pollutant, type, openness and price.")
set.caption(Caption)
panderOptions("table.emphasize.rownames", FALSE) # remove row.names from the table
panderOptions("table.split.table", Inf) # to avoid to split tables if rows are too long
panderOptions('table.alignment.default', function(df) ifelse(sapply(df, is.numeric), 'right', 'left')) # right alignment for numeric, left otherwise
pander(sensor_model_SS, emphasize.strong.cols = 1, table.emphasize.rownames = FALSE, missing = "")

# 

```


\newline

```{r Figure A1, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 7, fig.height = 7, fig.cap = "**Figure A1.** Distribution of $R^2$ for OEMs and sensor systems obtained from the calibration against the reference. Records were averaged over a time-scale of 1 hour. Dashed lines indicate the value of 0.7 and 1.0. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}

# compute frequency of records for each model of sensor
counts_r2_calibration_OEM_SS <- DB_calibration_OEM_SS_1hour %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))

color_living <- counts_r2_calibration_OEM_SS %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")

#======== Calibration plots for all pollutants (R2)

# plot <- ggplot(DB_calibration_OEM_SS_1hour, aes(x = fct_reorder(model, r2_calib, fun = median, .desc =TRUE), y = r2_calib)) +
  plot <- ggplot(DB_calibration_OEM_SS_1hour, aes(model, r2_calib)) +
  theme_bw() +
 geom_point(alpha=1, color="black", position = "jitter", size = 1) +
 # geom_boxplot(aes(fill = fct_reorder(model, r2_calib, fun = median, .desc =TRUE)), position = position_dodge2(preserve = "single")) +
    geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
 facet_grid(pollutant ~ ., labeller = label_parsed) +    
  # facet_grid(pollutant ~ living, labeller = label_parsed, scales = "free") +   
  guides(fill=FALSE) +   # no legend
  theme(legend.position="none") +
  # ylim(0, 1.2) +
  geom_hline(yintercept=1, linetype="dashed", color = "red") +
  geom_hline(yintercept=0.7, linetype="dashed", color = "red") +
  geom_text(data = counts_r2_calibration_OEM_SS, aes(x = model, y = 0.2, label = counts, fontface="bold", colour = factor(open_close)), size = 3,
            show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 13, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=13, colour=color_living , face="bold")) +  # colour = "black"
  ylab(expression(paste(R^2),size=40)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=13),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=10, colour = "black")) +
  ggtitle(expression(paste("Distribution of ", R^2, " from the CALIBRATION of OEMs and sensor systems (1 hour)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 12, hjust = 0.5)) 

plot



```

\newline

\newline


```{r Figure A2, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 7, fig.height = 7, fig.cap = "**Figure A2.** Distribution of $R^2$ for OEMs and ensor systems obtained from the calibration against the reference. Records were averaged over a time-scale of 1 minute. Dashed lines indicate the value of 0.7 and 1.0. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


# calibration models
DB_calibration <- DB[!(is.na(DB$r2_calib)), ]

# ...only for Sensor systems (both field and lab tests)
DB_calibration_OEM_SS_1min <- DB_calibration %>%
 # filter(OEM_system == "OEM") %>%
  filter(time_avg == "1 min")

levels(DB_calibration_OEM_SS_1min$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(DB_calibration_OEM_SS_1min$pollutant))
levels(DB_calibration_OEM_SS_1min$pollutant) <- gsub("^PM2$","PM2.5", levels(DB_calibration_OEM_SS_1min$pollutant))
levels(DB_calibration_OEM_SS_1min$pollutant) <- gsub("^PM3$","PM2.5", levels(DB_calibration_OEM_SS_1min$pollutant))
levels(DB_calibration_OEM_SS_1min$pollutant) <- gsub("^PM10-2.5$","PM10", levels(DB_calibration_OEM_SS_1min$pollutant))

levels(DB_calibration_OEM_SS_1min$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")

# compute frequency of records for each model of sensor
counts_r2_calibration_OEM_SS <- DB_calibration_OEM_SS_1min %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))


color_living <- counts_r2_calibration_OEM_SS %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")


#======== Calibration plots for all pollutants (R2)

plot <- ggplot(DB_calibration_OEM_SS_1min, aes(model, r2_calib)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 1) +
  geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +   
  guides(fill=FALSE) +   # no legend
  # ylim(0, 1.2) +
  geom_hline(yintercept=1, linetype="dashed", color = "red") +
  geom_hline(yintercept=0.7, linetype="dashed", color = "red") +
  geom_text(data = counts_r2_calibration_OEM_SS, aes(x = model, y = 0.2, label = counts, fontface="bold", colour = factor(open_close)), size = 4,
            show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 13, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=13, colour = color_living, face="bold")) +
  ylab(expression(paste(R^2),size=40)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=13),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=11, colour = "black")) +
  ggtitle(expression(paste("Distribution of ", R^2, " from the CALIBRATION of OEMs and sensor systems (1 minute)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 12, hjust = 0.5)) 

plot


```

\newline

```{r, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}

### Sensor Systems (1 hour)
# ...only for Sensor systems (both field and lab tests)
DB_comparison_SS_1minute <- DB %>%
  filter(OEM_system == "SS") %>%
  filter(time_avg == "1 min") %>%
  filter(! pollutant == "PM")

levels(DB_comparison_SS_1minute$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(DB_comparison_SS_1minute$pollutant))
levels(DB_comparison_SS_1minute$pollutant) <- gsub("^PM2$","PM2.5", levels(DB_comparison_SS_1minute$pollutant))
levels(DB_comparison_SS_1minute$pollutant) <- gsub("^PM3$","PM2.5", levels(DB_comparison_SS_1minute$pollutant))
levels(DB_comparison_SS_1minute$pollutant) <- gsub("^PM10-2.5$","PM10", levels(DB_comparison_SS_1minute$pollutant))
levels(DB_comparison_SS_1minute$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")

```


\newline


```{r Figure A3, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 8, fig.height = 8, fig.cap = "**Figure A3.** Distribution of $R^2$ from the comparison of sensor systems against reference systems. Records were averaged over a time-scale of 1 minute. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


# compute frequency of records for each model of sensor
counts_r2_comparison_SS <- DB_comparison_SS_1minute %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))


color_living <- counts_r2_comparison_SS %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")

#======== Comparison plots for all pollutants (R2)

plot <- ggplot(DB_comparison_SS_1hour, aes(model, r2)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 0.5) +
  geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +   
  guides(fill=FALSE) +   # no legend
  # ylim(0, 1) +
  geom_hline(yintercept=1, linetype="dashed", color = "red") +
  geom_hline(yintercept=0.7, linetype="dashed", color = "red") +
  geom_text(data = counts_r2_comparison_SS, aes(x = model, y = 0.25, label = counts, fontface="bold", colour = factor(open_close)), size = 3, show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 12, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=9, colour = color_living, face="bold")) +
  ylab(expression(paste(R^2),size=13)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=13),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=10, colour = "black")) +
  ggtitle(expression(paste("Distribution of ", R^2, " from COMPARISON with reference systems for sensor systems (1 minute)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 12, hjust = 0.5)) 

plot

```

\newline

```{r Figure A4, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 7, fig.height = 8, fig.cap = "**Figure A4.** Distribution of $R^2$ from the comparison of sensor systems against reference systems. Records were averaged over a time-scale of 1 hour. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


# compute frequency of records for each model of sensor
counts_r2_comparison_SS <- DB_comparison_SS_1hour %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))


color_living <- counts_r2_comparison_SS %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")

#======== Comparison plots for all pollutants (R2)

plot <- ggplot(DB_comparison_SS_1hour, aes(model, r2)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 0.5) +
  geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +   
  guides(fill=FALSE) +   # no legend
  # ylim(0, 1) +
  geom_hline(yintercept=1, linetype="dashed", color = "red") +
  geom_hline(yintercept=0.7, linetype="dashed", color = "red") +
  geom_text(data = counts_r2_comparison_SS, aes(x = model, y = 0.25, label = counts, fontface="bold", colour = factor(open_close)), size = 3, show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 12, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=9, colour = color_living, face="bold")) +
  ylab(expression(paste(R^2),size=13)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=13),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=10, colour = "black")) +
  ggtitle(expression(paste("Distribution of ", R^2, " from COMPARISON with reference systems for sensor systems (1 hour)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 12, hjust = 0.5)) 

plot

```

\newline


```{r Figure A5, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 13, fig.height = 14, fig.cap = "**Figure A5.** Distribution of $R^2$ from the comparison of OEMs against reference systems. Records were averaged over a time-scale of 1 hour. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


levels(DB_comparison_OEM_1hour$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(DB_comparison_OEM_1hour$pollutant))
levels(DB_comparison_OEM_1hour$pollutant) <- gsub("^PM2$","PM2.5", levels(DB_comparison_OEM_1hour$pollutant))
levels(DB_comparison_OEM_1hour$pollutant) <- gsub("^PM3$","PM2.5", levels(DB_comparison_OEM_1hour$pollutant))
levels(DB_comparison_OEM_1hour$pollutant) <- gsub("^PM10-2.5$","PM10", levels(DB_comparison_OEM_1hour$pollutant))
levels(DB_comparison_OEM_1hour$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")


levels(DB_comparison_OEM_1hour$pollutant) <- gsub("^PM2.5$","$PM_{2.5}$", levels(DB_comparison_OEM_1hour$pollutant))
levels(DB_comparison_OEM_1hour$pollutant) <- gsub("^PM10$","$PM_{10}$", levels(DB_comparison_OEM_1hour$pollutant))
levels(DB_comparison_OEM_1hour$pollutant)<-  gsub("^PM1$","$PM_{1}$", levels(DB_comparison_OEM_1hour$pollutant))
levels(DB_comparison_OEM_1hour$pollutant) <- gsub("^NO2$","$NO_{2}$", levels(DB_comparison_OEM_1hour$pollutant))
levels(DB_comparison_OEM_1hour$pollutant) <- gsub("^O3$","$O_{3}$", levels(DB_comparison_OEM_1hour$pollutant))

# compute frequency of records for each model of sensor
counts_r2_comparison_OEM <- DB_comparison_OEM_1hour %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))

color_living <- counts_r2_comparison_OEM %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")



#======== Comparison plots for all pollutants (R2)


plot <- ggplot(DB_comparison_OEM_1hour, aes(model, r2)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 2) +
  geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +   
  guides(fill=FALSE) +   # no legend
  # ylim(0, 1) +
  geom_hline(yintercept=1, linetype="dashed", color = "red") +
  geom_hline(yintercept=0.7, linetype="dashed", color = "red") +
  geom_text(data = counts_r2_comparison_OEM, aes(x = model, y = 0.25, label = counts, fontface="bold", colour = factor(open_close)), size = 5, show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 20, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=18, colour = color_living, face="bold")) +
  ylab(expression(paste(R^2),size=40)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=22),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=18, colour = "black")) +
  ggtitle(expression(paste("Distribution of ", R^2, " from COMPARISON with reference systems for OEMs (1 hour)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 25, hjust = 0.5)) 

plot

```

\newline


```{r Figure A6, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 8, fig.height = 10, fig.cap = "**Figure A6.** Distribution of $R^2$ from the comparison of OEMs against reference systems. Records were averaged over a time-scale of 24 hour. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


# compute frequency of records for each model of sensor
counts_r2_comparison_OEM <- DB_comparison_OEM_24hour %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))

color_living <- counts_r2_comparison_OEM %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")


#======== Comparison plots for all pollutants (R2)

plot <- ggplot(DB_comparison_OEM_24hour, aes(model, r2)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 2) +
  geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +   
  guides(fill=FALSE) +   # no legend
  # ylim(0, 1) +
  geom_hline(yintercept=1, linetype="dashed", color = "red") +
  geom_hline(yintercept=0.7, linetype="dashed", color = "red") +
  geom_text(data = counts_r2_comparison_OEM, aes(x = model, y = 0.2, label = counts, fontface="bold", colour = factor(open_close)), size = 4, show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 20, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=18, colour = color_living, face="bold")) +
  ylab(expression(paste(R^2),size=40)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=18),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=18, colour = "black")) +
  ggtitle(expression(paste("Distribution of ", R^2, " from COMPARISON with reference systems for OEMs (24 hour)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 12, hjust = 0.5)) 

plot

```

\newline

```{r Figure A7, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 10, fig.height = 13, fig.cap = "**Figure A7.** Distribution of $R^2$ from the comparison of sensor systems against reference systems. Records were averaged over a time-scale of 24 hour. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


levels(DB_comparison_SS_24hour$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(DB_comparison_SS_24hour$pollutant))
levels(DB_comparison_SS_24hour$pollutant) <- gsub("^PM2$","PM2.5", levels(DB_comparison_SS_24hour$pollutant))
levels(DB_comparison_SS_24hour$pollutant) <- gsub("^PM3$","PM2.5", levels(DB_comparison_SS_24hour$pollutant))
levels(DB_comparison_SS_24hour$pollutant) <- gsub("^PM10-2.5$","PM10", levels(DB_comparison_SS_24hour$pollutant))
levels(DB_comparison_SS_24hour$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")


levels(DB_comparison_SS_24hour$pollutant) <- gsub("^PM2.5$","$PM_{2.5}$", levels(DB_comparison_SS_24hour$pollutant))
levels(DB_comparison_SS_24hour$pollutant) <- gsub("^PM10$","$PM_{10}$", levels(DB_comparison_SS_24hour$pollutant))
levels(DB_comparison_SS_24hour$pollutant)<-  gsub("^PM1$","$PM_{1}$", levels(DB_comparison_SS_24hour$pollutant))
levels(DB_comparison_SS_24hour$pollutant) <- gsub("^NO2$","$NO_{2}$", levels(DB_comparison_SS_24hour$pollutant))
levels(DB_comparison_SS_24hour$pollutant) <- gsub("^O3$","$O_{3}$", levels(DB_comparison_SS_24hour$pollutant))

# compute frequency of records for each model of sensor
counts_r2_comparison_SS <- DB_comparison_SS_24hour %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))

color_living <- counts_r2_comparison_SS %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")

#======== Comparison plots for all pollutants (R2)

plot <- ggplot(DB_comparison_SS_24hour, aes(model, r2)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 1) +
  geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +   
  guides(fill=FALSE) +   # no legend
  # ylim(0, 1) +
  geom_hline(yintercept=1, linetype="dashed", color = "red") +
  geom_hline(yintercept=0.7, linetype="dashed", color = "red") +
  geom_text(data = counts_r2_comparison_SS, aes(x = model, y = 0.2, label = counts, fontface="bold", colour = factor(open_close)), size = 4,     show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 20, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=18, colour = color_living, face="bold")) +
  ylab(expression(paste(R^2),size=40)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=20),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=18, colour = "black")) +
  ggtitle(expression(paste("Distribution of ", R^2, " from COMPARISON with reference systems for sensor systems (24 hour)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 15, hjust = 0.5)) 

plot

```

\newline


```{r Figure A8, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 9, fig.height = 9, fig.cap = "**Figure A8.** Distribution of slopes from the comparison of sensors systems against the reference. Only records with $R^2$ > 0.7 and 0.5 < slope < 1.5 are shown. Records were averaged over a time-scale of 1 hour. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


#========Validation plot for SS (slope) 

count_DB_comparison_SS_filtered <- DB_comparison_SS_1hour_filtered %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))

color_living <- count_DB_comparison_SS_filtered %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")



DB_comparison_SS_1hour_filtered$new_slope <- round(DB_comparison_SS_1hour_filtered$new_slope, digits=4)
# order new_slope from small to big
# DB_comparison_SS_filtered <- DB_comparison_SS_filtered[order(-DB_comparison_SS_filtered$new_slope),]


levels(DB_comparison_SS_1minute$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")


plot <- ggplot(DB_comparison_SS_1hour_filtered, aes(model, new_slope)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 1) +
  geom_boxplot(aes(fill = new_slope), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +
  guides(fill=FALSE) +   # no legend
  # ylim(0, 2) +
  geom_hline(yintercept=0.5, linetype="dashed", color = "red") +
  geom_hline(yintercept=1.0, linetype="dashed", color = "blue") +
  geom_hline(yintercept=1.5, linetype="dashed", color = "red") +
  geom_text(data = count_DB_comparison_SS_filtered, aes(x = model, y = 1.2, label = counts, fontface="bold", colour = factor(open_close)), size = 4,     show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 20, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  # ylab("slope") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=15, colour = color_living, face="bold")) +
  ylab(expression("slope",size=30)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=22),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=13, colour = "black")) +
  ggtitle(expression(paste("Distribution of slopes", " for sensors systems: COMPARISON with REFERENCE (1 hour)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 15, hjust = 0.5)) 

plot

```

\newline



```{r Figure A9, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 7, fig.height = 6, fig.cap = "**Figure A9.** Distribution of slopes from the comparison of OEMs against the reference. Only records with $R^2$ > 0.7 and 0.5 < slope < 1.5 are shown.  Records were averaged over a time-scale of 1 hour. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


#========Validation plot for OEMs (slope) 


levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^PM2$","PM2.5", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^PM3$","PM2.5", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^PM10-2.5$","PM10", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")


levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^PM2.5$","$PM_{2.5}$", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^PM10$","$PM_{10}$", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant)<- gsub("^PM1$","$PM_{1}$", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^NO2$","$NO_{2}$", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^O3$","$O_{3}$", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^CO$","$CO$", levels(DB_comparison_OEM_1hour_filtered$pollutant))
levels(DB_comparison_OEM_1hour_filtered$pollutant) <- gsub("^NO$","$NO$", levels(DB_comparison_OEM_1hour_filtered$pollutant))


count_DB_comparison_OEM_filtered <- DB_comparison_OEM_1hour_filtered %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))

color_living <- count_DB_comparison_OEM_filtered %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")


DB_comparison_OEM_1hour_filtered$new_slope <- round(DB_comparison_OEM_1hour_filtered$new_slope, digits=4)
# order new_slope from small to big
# DB_comparison_OEM_filtered <- DB_comparison_OEM_filtered[order(-DB_comparison_OEM_filtered$new_slope),]

plot <- ggplot(DB_comparison_OEM_1hour_filtered, aes(model, new_slope)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 1) +
  geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +
  guides(fill=FALSE) +   # no legend
  # ylim(0, 2) +
  geom_hline(yintercept=0.5, linetype="dashed", color = "red") +
  geom_hline(yintercept=1.0, linetype="dashed", color = "blue") +
  geom_hline(yintercept=1.5, linetype="dashed", color = "red") +
   geom_text(data = count_DB_comparison_OEM_filtered, aes(x = model, y = 0.75, label = counts, fontface="bold", colour = factor(open_close)), size = 5,     show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 15, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  ylab("slope") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=15, colour = color_living, face="bold")) +
  # ylab(expression(paste(R^2),size=40)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=15),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=15, colour = "black")) +
  ggtitle(expression(paste("Distribution of slopes", " for OEMs: COMPARISON with REFERENCE (1 hour)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 10, hjust = 0.5)) 

plot

```

\newline


```{r Figure A10, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 9, fig.height = 9, fig.cap = "**Figure A10.** Distribution of slopes from the comparison of sensors systems against the reference. Only records with $R^2$ > 0.7 and 0.5 < slope < 1.5 are shown. Records were averaged over a time-scale of 24 hour. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


#========Validation plot for SS (slope) 

levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^PM2.5-0.5$","PM2.5", levels(DB_comparison_SS_24hour_filtered$pollutant))
levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^PM2$","PM2.5", levels(DB_comparison_SS_24hour_filtered$pollutant))
levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^PM3$","PM2.5", levels(DB_comparison_SS_24hour_filtered$pollutant))
levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^PM10-2.5$","PM10", levels(DB_comparison_SS_24hour_filtered$pollutant))
levels(DB_comparison_SS_24hour_filtered$pollutant) <-  c("CO","NO", "NO[2]", "O[3]", "PM", "PM[1]", "PM[10]",  "PM[2.5]")


levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^PM2.5$","$PM_{2.5}$", levels(DB_comparison_SS_24hour_filtered$pollutant))
levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^PM10$","$PM_{10}$", levels(DB_comparison_SS_24hour_filtered$pollutant))
levels(DB_comparison_SS_24hour_filtered$pollutant)<- gsub("^PM1$","$PM_{1}$", levels(DB_comparison_SS_24hour_filtered$pollutant))
levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^NO2$","$NO_{2}$", levels(DB_comparison_SS_24hour_filtered$pollutant))
levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^O3$","$O_{3}$", levels(DB_comparison_SS_24hour_filtered$pollutant))
# levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^CO$","$CO$", levels(DB_comparison_SS_24hour_filtered$pollutant))
levels(DB_comparison_SS_24hour_filtered$pollutant) <- gsub("^NO$","$NO$", levels(DB_comparison_SS_24hour_filtered$pollutant))

count_DB_comparison_SS_filtered <- DB_comparison_SS_24hour_filtered %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))

color_living <- count_DB_comparison_SS_filtered %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")


DB_comparison_SS_24hour_filtered$new_slope <- round(DB_comparison_SS_24hour_filtered$new_slope, digits=4)
# order new_slope from small to big
# DB_comparison_SS_filtered <- DB_comparison_SS_filtered[order(-DB_comparison_SS_filtered$new_slope),]

plot <- ggplot(DB_comparison_SS_24hour_filtered, aes(model, new_slope)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 1) +
  geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +
  guides(fill=FALSE) +   # no legend
  # ylim(0, 2) +
  geom_hline(yintercept=0.5, linetype="dashed", color = "red") +
  geom_hline(yintercept=1.0, linetype="dashed", color = "blue") +
  geom_hline(yintercept=1.5, linetype="dashed", color = "red") +
  geom_text(data = count_DB_comparison_SS_filtered, aes(x = model, y = 1.3, label = counts, fontface="bold", colour = factor(open_close)), size = 4,     show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 20, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  ylab(expression("slope",size=30)) + 
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=18, colour = color_living, face="bold")) +
  # ylab(expression(paste(R^2),size=40)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=20),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=13, colour = "black")) +
  ggtitle(expression(paste("Distribution of slopes", " for sensors systems: COMPARISON with REFERENCE (24 hour)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 15, hjust = 0.5)) 

plot

```

\newline


```{r Figure A11, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 7, fig.height = 7, fig.cap = "**Figure A11.** Distribution of slopes from the comparison of OEMs against the reference. Only records with $R^2$ > 0.7 and 0.5 < slope < 1.5 are shown.  Records were averaged over a time-scale of 24 hour. Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


#========Validation plot for OEMs (slope) 


count_DB_comparison_OEM_filtered <- DB_comparison_OEM_24hour_filtered %>%
  group_by(model,
           pollutant,
           open_close,
           living) %>%
  summarise(counts = length(model))

color_living <- count_DB_comparison_OEM_filtered %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")


DB_comparison_OEM_24hour_filtered$new_slope <- round(DB_comparison_OEM_24hour_filtered$new_slope, digits=4)
# order new_slope from small to big
# DB_comparison_OEM_filtered <- DB_comparison_OEM_filtered[order(-DB_comparison_OEM_filtered$new_slope),]

plot <- ggplot(DB_comparison_OEM_24hour_filtered, aes(model, new_slope)) +
  theme_bw() +
  geom_point(alpha=1, color="black", position = "jitter", size = 1) +
  geom_boxplot(aes(fill = model), position = position_dodge2(preserve = "single")) +
  facet_grid(pollutant ~ ., labeller = label_parsed) +
  guides(fill=FALSE) +   # no legend
  # ylim(0, 2) +
  geom_hline(yintercept=0.5, linetype="dashed", color = "red") +
  geom_hline(yintercept=1.0, linetype="dashed", color = "blue") +
  geom_hline(yintercept=1.5, linetype="dashed", color = "red") +
    geom_text(data = count_DB_comparison_OEM_filtered, aes(x = model, y = 0.75, label = counts, fontface="bold", colour = factor(open_close)), size = 4,     show.legend = FALSE) + #colour="red", fontface=2, colour = factor(open_close)
  scale_color_manual(values =c('black', "blue"),guide="none") +
  theme(strip.text = element_text(size = 20, face="bold")) + 
  theme(strip.text.y = element_text(angle = 0)) +
  xlab("Sensor Model") +
  ylab("slope") +
  theme(axis.title.x=element_blank(),
        axis.text.x  = element_text(angle=90, vjust=0.5, hjust = 1, size=18, colour = color_living, face="bold")) +
  # ylab(expression(paste(R^2),size=40)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=20),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=18, colour = "black")) +
  ggtitle(expression(paste("Distribution of slopes", " for OEMs: COMPARISON with REFERENCE (24 hour)"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 12, hjust = 0.5)) 

plot

```


\newline



```{r Figure A12, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 12, fig.height = 12, fig.cap = "**Figure A12.** Mean $slope$ for obtained from the comparison of OEMs and sensor systems against reference measurements."}

DB_comparison_slope <- DB[!(is.na(DB$slope)), ]

DB_comparison_slope$new_slope <- DB_comparison_slope$slope

for (i in 1:nrow(DB_comparison_slope)) {
if  (DB_comparison_slope$y[i] == "Sensor") {
  DB_comparison_slope$new_slope[i] = 1/DB_comparison_slope$slope[i]
} else DB_comparison_slope$new_slope[i] = DB_comparison_slope$slope[i]
}

DB_comparison_slope <- DB_comparison_slope %>%
   filter(r2 > 0.75 & new_slope > 0.5 & new_slope < 1.2)

# summarize by reference
DB_comparison_slope <- DB_comparison_slope %>%
  group_by(new_ref_author,
           model) %>%
  summarise(mean_slope_comparison = mean(new_slope))



# create a new referecne with number (ID) of the reference and first author name
DB_comparison_slope$id_ref_new <- NULL
# DB_comparison_slope$id_ref_new <- paste0("[", DB_comparison_slope$id_ref, "]")
DB_comparison_slope$id_ref_new <- DB_comparison_slope$new_ref_author

#======== Calibration plots for all pollutants (R2)


plot <- ggplot(DB_comparison_slope, aes(mean_slope_comparison, model)) +
  theme_bw() +
   theme(panel.grid.major.y = element_line(colour="grey", size = 1, linetype="dashed"),
        panel.grid.major.x = element_line(colour="grey", size = 1)) +
  geom_point(alpha=1, color="black", size = 4) + 
  geom_line(size = 2) +
   geom_text_repel(aes(label=id_ref_new), size = 5, show.legend = FALSE) +
  ylab("Sensor Model") +
  scale_y_discrete(expand=c(0.01, 0.6)) +
  xlim(0.25, 1.05) +
  xlab(expression(paste("slope"),size=40)) + 
  geom_vline(xintercept=1.0, linetype="dashed", color = "red", size = 1.5) +
  theme(axis.title.y = element_text(face="bold", colour="black", size=22, margin = margin(t = 0, r = 20, b = 0, l = 0)),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=15, colour = "black")) +
   theme(axis.title.x = element_text(colour="black", size=20),
        axis.text.x  = element_text(angle=0, vjust=0.5, hjust = 0.5, size=15, colour = "black")) +
  # ggtitle(expression(paste("Mean value of slope from the COMPARISON of OEMs and sensor systems against reference"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 18, hjust = 0.5)) 
plot



```


\newline


```{r Figure A13, echo = FALSE, warning = FALSE, cache = FALSE, results = 'asis', message = FALSE, comment=FALSE, fig.width = 10, fig.height = 11, fig.cap = "**Figure A13.** Prices of OEMs available on the market (Numbers in bold indicates the number of pollutant measured by each sensor. x-axis uses logarithmic scale). Numbers in bold indicate the number of open source (blue) and black box (black) records. Names of 'living' and 'non-living' sensors are indicated in black and red color, respectively."}


#======== prices of OEMs 


# slect OEMs
DB_OEM <- DB %>%
  filter(OEM_system == "OEM") 

OEM_prices <- DB_OEM[!(is.na(DB_OEM$price)), ]
OEM_prices <- as.data.frame(OEM_prices)

# make all new prices in EUR
for (i in 1:nrow(OEM_prices)) {
  if  (OEM_prices$currency[i] == "USD") {
    OEM_prices$new_price_EUR[i] = round(0.88*OEM_prices$price[i], digits = 0)
  } else OEM_prices$new_price_EUR[i] = round(OEM_prices$price[i], digits = 0)
}


OEM_prices <- OEM_prices %>%
  filter(# new_price_EUR < 2500,
         # !living == "N",
          !pollutant == "PM10-2.5",
          !pollutant == "PM2.5-0.5",
          !pollutant == "PM2",
          !pollutant == "PM3",
          new_price_EUR > 0) 
# order in alphabetic order
OEM_prices <- OEM_prices[order(OEM_prices$model),]



# number of pollutants measured by each sensor
count_OEM_prices <- OEM_prices[!duplicated(OEM_prices[c("model", "pollutant" )]),]
count_OEM_prices <- count_OEM_prices %>%
    group_by(model,
             open_close,
             living,
             commercial) %>%
    summarise(counts = length(pollutant))

# select unique PRICE and POLLUTANT per model of sensor
OEM_prices <- OEM_prices[!duplicated(OEM_prices[c("model", "price")]),]
OEM_prices <- OEM_prices %>%
  group_by(model) %>%
  summarise(new_price_EUR = mean(new_price_EUR))
count_OEM_prices <- count_OEM_prices[!duplicated(count_OEM_prices[c("model")]),]
count_OEM_prices <- as.data.frame(count_OEM_prices)


price_EUR <- as.data.frame(OEM_prices$new_price_EUR)
# names(price_EUR) <- "new_price_EUR"

count_OEM_prices <- cbind(count_OEM_prices, price_EUR)

color_living <- count_OEM_prices %>%
  group_by(model,
           living) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living %in% c("Y", "updated"), "black", "red")


#plot <- ggplot(OEM_prices, aes(reorder(model, new_price_EUR), new_price_EUR, fill = new_price_EUR)) +
plot <- ggplot(OEM_prices, aes(model, new_price_EUR)) +
  theme_bw() +
  geom_bar(stat = "identity", fill = "gray", color= "black") +
  coord_flip() +
  guides(fill=FALSE) +   # no legend
  scale_y_continuous(trans='log10', breaks =c(5, 10, 30, 50, 150, 1000, 10000), limits = c(6, 10000), oob = rescale_none) +
  # xlab("model") +
  xlab(expression(paste("model"),size=50)) +
  geom_text(data = count_OEM_prices, aes(x = model, y = 11000, label = counts, fontface="bold", colour = factor(open_close)), size = 4, show.legend = FALSE) +
    geom_text(data = count_OEM_prices, aes(x = model, y = 5000, label = commercial, fontface="bold", colour = factor(commercial)), size = 4, show.legend = FALSE) +
  scale_color_manual(values =c('black', "black", "blue", "black"),guide="none") +
  theme(axis.title.x=element_text(face="bold", colour="black", size=14),
        axis.text.x = element_text(angle=0, vjust=1, hjust = 0.5, size=15, colour = "black", face="bold")) +
  ylab(expression(paste("Price (EUR)"),size=30)) + 
  theme(axis.title.y = element_text(face="bold", colour="black", size=20),
        axis.text.y  = element_text(angle=0, vjust=0.5, size=18, colour =  color_living)) +
  ggtitle(expression(paste("Average prices of reviewed OEMs"))) + 
  theme(plot.title = element_text(lineheight=.8, face="bold", size = 15, hjust = 0.5)) 

plot

```


\newline


```{r Table A4, echo = FALSE, warning = FALSE, cache = FALSE, out.width = "70%", results = 'asis', message = FALSE, comment=FALSE}

# remove NA values
DB_prices <- DB[!is.na(DB$price & DB$slope & DB$intercept), ]

# only 1 hour averaged data
DB_prices <- DB_prices %>%
  filter(time_avg %in% c("1 hour", "24 hour"))


DB_prices$new_slope     <- DB_prices$slope
DB_prices$new_intercept <- DB_prices$intercept

Inversion.row <- which(DB_prices$y == "Sensor")

if(length(Inversion.row) > 0) {
    DB_prices[Inversion.row,"new_slope"] <-  1/DB_prices[Inversion.row,"slope"]
    DB_prices[Inversion.row,"new_intercept"] <- - DB_prices[Inversion.row, "intercept"]/DB_prices[Inversion.row,"slope"]
}


# make all new prices in EUR
for (i in 1:nrow(DB_prices)) {
  if  (DB_prices$currency[i] == "USD") {
    DB_prices$new_price_EUR[i] = 0.88*DB_prices$price[i]
  } else DB_prices$new_price_EUR[i] = round(DB_prices$price[i], digits = 0)
}

count_DB_prices <- DB_prices[!duplicated(DB_prices[c("model", "pollutant", "time_avg" )]),]
count_DB_prices <- count_DB_prices %>%
    group_by(model,
             open_close,
             living,
             commercial,
             new_price_EUR,
             time_avg) %>%
    summarise(counts = length(pollutant))

n_price <- count_DB_prices[!is.na(count_DB_prices$new_price_EUR),]


# filter sensors with R2 > 0.7 and 0.5< slope< 1.5
DB_prices <- DB_prices %>%
  filter(r2 > 0.85 & new_slope > 0.8 & new_slope < 1.2)


# only select sensor systems
DB_prices <- DB_prices %>%
  filter(OEM_system == "SS")


# select prices <= 2500 EUR
DB_prices <- DB_prices %>%
  filter(# new_price_EUR < 2500,
         # !living == "N",
          !pollutant == "PM10-2.5",
          !pollutant == "PM2.5-0.5",
          !pollutant == "PM2",
          !pollutant == "PM3",
          new_price_EUR > 0)
# order in alphabetic order
DB_prices <- DB_prices[order(DB_prices$model),]

all_DB_prices <- DB_prices


# select unique PRICE and POLLUTANT per model of sensor
DB_prices <- DB_prices[!duplicated(DB_prices[c("model", "price", "time_avg")]),]
count_DB_prices <- count_DB_prices[!duplicated(count_DB_prices[c("model", "time_avg")]),]
count_DB_prices <- as.data.frame(count_DB_prices)

DB_prices <- DB_prices %>%
  left_join(count_DB_prices, c("model" , "time_avg"))

DB_prices <- DB_prices %>%
  select(model,
         open_close.x,
         living.x,
         commercial.x,
         counts,
         new_price_EUR.x,
         time_avg)

color_living <- DB_prices %>%
  group_by(model,
           living.x) %>%
  summarize(counts = length(count))
            
color_living <- ifelse(color_living$living.x %in% c("Y", "updated"), "black", "red")

  
  # only select sensor systems with  (all possible pollutants)
  names <- count_DB_prices[count_DB_prices$counts >= 0, ]$model
  names <- as.character(names)
  DB_prices <- DB_prices[DB_prices$model %in% names,]
  


# filter data with AVERAGING TIME  == 24 hour
SS_price_pollutants <- DB_prices %>%
  filter(time_avg == "24 hour")

# identify pollutants measured by each sensor

SS_price_pollutants <- as.data.frame(SS_price_pollutants[,1])
names(SS_price_pollutants) <- "model" 


all_DB_prices_24h <- all_DB_prices %>%
    filter(time_avg == "24 hour")

SS_price_pollutants <- SS_price_pollutants %>%
  left_join(all_DB_prices_24h, c("model"))


# make all new prices in EUR
for (i in 1:nrow(SS_price_pollutants)) {
  if  (SS_price_pollutants$currency[i] == "USD") {
    SS_price_pollutants$new_price_EUR[i] = round(0.88*SS_price_pollutants$price[i], digits = 0)
  } else SS_price_pollutants$new_price_EUR[i] = round(SS_price_pollutants$price[i], digits = 0)
}


SS_price_pollutants <- SS_price_pollutants %>%
  select(-price)
# rename "new_price_EUR"" into "price""
names(SS_price_pollutants)[names(SS_price_pollutants)=="new_price_EUR"] <- "price"


means <- SS_price_pollutants %>%
  group_by(model) %>%
  summarise(mean_r2 = format(mean(r2, na.rm = T), digits = 2),
            mean_slope = format(mean(new_slope, na.rm = T), digits = 2),
            mean_intercept = format(mean(abs(new_intercept), na.rm = T), digits = 2))


SS_price_pollutants <- SS_price_pollutants %>%
  group_by(model,
         open_close,
         living,
         commercial,
         pollutant,
         price) %>%
  summarise(mean_r2 = format(mean(r2, na.rm = T), digits = 2),
            mean_slope = format(mean(new_slope, na.rm = T), digits = T),
            mean_intercept = format(mean(new_intercept, na.rm = T), digits = T))
            

SS_price_pollutants <- SS_price_pollutants %>%
  filter(!pollutant == "PM10-2.5",
          !pollutant == "PM2.5-0.5",
          !pollutant == "PM2",
          !pollutant == "PM3")


# select unique model and pollutant per model of sensor
SS_price_pollutants <- SS_price_pollutants[!duplicated(SS_price_pollutants[c("model", "price", "pollutant")]),]

SS_price_pollutants <- SS_price_pollutants %>%
  select(model,
         open_close,
         living,
         commercial,
         pollutant,
         price,
         mean_r2,
         mean_slope,
         mean_intercept)

# change names
levels(SS_price_pollutants$commercial) <- gsub("^NC$","non commercial", levels(SS_price_pollutants$commercial))
levels(SS_price_pollutants$commercial) <- gsub("^$","commercial", levels(SS_price_pollutants$commercial))
levels(SS_price_pollutants$pollutant) <- gsub("^PM2.5$","$PM_{2.5}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^PM10$","$PM_{10}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^PM1$","$PM_{1}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^NO2$","$NO_{2}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^O3$","$O_{3}$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^CO$","$CO$", levels(SS_price_pollutants$pollutant))
levels(SS_price_pollutants$pollutant) <- gsub("^NO$","$NO$", levels(SS_price_pollutants$pollutant))

#only PM2.5
SS_price_pollutants_PM25 <- SS_price_pollutants %>%
  filter(pollutant == "$PM_{2.5}$")

#only PM10
SS_price_pollutants_PM10 <- SS_price_pollutants %>%
  filter(pollutant == "$PM_{10}$")

#only PM1
SS_price_pollutants_PM1 <- SS_price_pollutants %>%
  filter(pollutant == "$PM_{1}$")

#only NO2
SS_price_pollutants_NO2 <- SS_price_pollutants %>%
  filter(pollutant == "$NO_{2}$")

#only O3
SS_price_pollutants_O3 <- SS_price_pollutants %>%
  filter(pollutant == "$O_{3}$")

#only CO
SS_price_pollutants_CO <- SS_price_pollutants %>%
  filter(pollutant == "$CO$")

#only NO
SS_price_pollutants_NO <- SS_price_pollutants %>%
  filter(pollutant == "$NO$")

AAA <- SS_price_pollutants_PM25 %>%
  full_join(SS_price_pollutants_PM10, c("model")) 

BBB <- AAA %>%
  full_join(SS_price_pollutants_PM1, c("model")) 

CCC <- BBB %>%
  full_join(SS_price_pollutants_NO2, c("model")) 

DDD <- CCC %>%
  full_join(SS_price_pollutants_O3, c("model")) 

EEE <- DDD %>%
  full_join(SS_price_pollutants_CO, c("model")) 

FFF <- EEE %>%
  full_join(SS_price_pollutants_NO, c("model"))


FFF <- as.data.frame(FFF)

FFF <- FFF %>%
  select(-price,
         -price.x,
         -price.x.x,
         -price.x.x.x,
         -price.y,
         -price.y.y,
         -price.y.y.y,
         -open_close,
         - open_close.x,
         - open_close.x.x,
         - open_close.x.x.x,
         - open_close.y,
         - open_close.y.y,
         - open_close.y.y.y,
         - living,
         - living.x,
         - living.x.x,
         - living.x.x.x,
         - living.y,
         - living.y.y,
         - living.y.y.y,
         - commercial,
         - commercial.x,
         - commercial.x.x,
         - commercial.x.x.x,
         - commercial.y,
         - commercial.y.y,
         - commercial.y.y.y,
         - mean_r2,
         - mean_r2.x,
         - mean_r2.x.x,
         - mean_r2.x.x.x,
         - mean_r2.y,
         - mean_r2.y.y,
         - mean_r2.y.y.y,
         - mean_slope,
         - mean_slope.x,
         - mean_slope.x.x,
         - mean_slope.x.x.x,
         - mean_slope.y,
         - mean_slope.y.y,
         - mean_slope.y.y.y,
         - mean_intercept,
         - mean_intercept.x,
         - mean_intercept.x.x,
         - mean_intercept.x.x.x,
         - mean_intercept.y,
         - mean_intercept.y.y,
         - mean_intercept.y.y.y)

# aggregate all pollutants into one column
# df$variable_7 <- apply(df, 1, function(x) paste(x[!is.na(x) & x != "No"], collapse = ", "))
FFF$pollutant <- apply(FFF[2:8], 1, function(x) paste(x[!is.na(x)], collapse = ", "))
FFF <- FFF %>%
  select(model,
         pollutant)


# merge with  price
SS_price_pollutants <- SS_price_pollutants[!duplicated(SS_price_pollutants[c("model", "price", "open_close", "living", "commercial")]),]

FFF <- FFF[order(FFF$model),]
SS_price_pollutants <- cbind(FFF,
                             means$mean_r2,
                             means$mean_slope,
                             means$mean_intercept,
                             SS_price_pollutants$open_close,
                             SS_price_pollutants$living,
                             SS_price_pollutants$commercial,
                             SS_price_pollutants$price)

colnames(SS_price_pollutants) <- c("model", "pollutant", "mean $R^{2}$", "mean slope","mean intercept",  "open/close", "living", "commercial", "price (EUR)")
# sort by price
SS_price_pollutants <- SS_price_pollutants[order(SS_price_pollutants$price),]

rownames(SS_price_pollutants) <- NULL

Caption <- paste0("**Table S7.** Shortlist of sensor systems showing good agreement with reference systems ($R^2$ > 0.85; 0.8 < slope < 1.2) for 24 hour time averaged data.")
set.caption(Caption)
panderOptions("table.emphasize.rownames", FALSE) # remove row.names from the table
panderOptions("table.split.table", Inf) # to avoid to split tables if rows are too long
panderOptions('table.alignment.default', function(df) ifelse(sapply(df, is.numeric), 'right', 'left')) # right alignment for 
pander(SS_price_pollutants, emphasize.strong.cols = 1, missing = "")

```


\newline

*** end of the document ***

## Bibliography
